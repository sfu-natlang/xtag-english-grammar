%talk about ECM and object control verbs
%being treated the same (at least, sharing a tree family).
%format for features? angle brackets or no

\chapter{Sentential Subjects and Sentential Complements}
\label{scomps-section}

In the XTAG grammar, arguments of a lexical item, including
subjects, appear in the initial tree anchored by that lexical item.  A
sentential argument appears as an S node in the appropriate position
within an elementary tree anchored by the lexical item that selects
it. This is the case for sentential complements of verbs, prepositions
and nouns and for sentential subjects. The distribution of
complementizers in English is intertwined with the distribution of
embedded sentences.  A successful analysis of complementizers in
English must handle both the cooccurrence restrictions between
complementizers and various types of clauses, and the distribution of
the clauses themselves, in both subject and complement positions.

\section{S or VP complements?}
 
Two comparable grammatical formalisms, Generalized Phrase Structure
Grammar (GPSG) \cite{gazdar85} and Head-driven Phrase Structure
Grammar (HPSG) \cite{PollardSag94:BK}, have rather different
treatments of sentential complements (S-comps).  They both treat
embedded sentences as VP's with subjects, which generates the correct
structures but misses the generalization that S's behave similarly in
both matrix and embedded environments, and VP's behave quite
differently.  Neither account has PRO\label{PRO} subjects of
infinitival clauses-- they have subjectless VP's instead.  GPSG has a
complete complementizer system, which appears to cover the same range
of data as our analysis.  It is not clear what sort of complementizer
analysis could be implemented in HPSG.

Following standard GB approach, the English XTAG grammar does not
allow VP complements but treats verb-anchored structures without overt
subjects as having PRO subjects. Thus, indicative clauses, infinitives
and gerunds all have a uniform treatment as embedded clauses using the
same trees under this approach. Furthermore, our analysis is able to
preserve the selectional and distributional distinction between S's and
VP's, in the spirit of GB theories, without having to posit `extra'
empty categories.\footnote{i.e. empty complementizers. We do have PRO
and NP traces in the grammar.} Consider the alternation between {\it
that} and the null complementizer\footnote{Although we will continue
to refer to `null' complementizers, in our analysis this is actually
the absence of a complementizer.}, shown in sentences~(\ex{1}) and (\ex{2}).

\enumsentence{He hopes $\emptyset$ Muriel wins.}
\enumsentence{He hopes that Muriel wins.}

 In GB both {\it Muriel wins} in (\ex{-1}) and {\it that Muriel wins} in
(\ex{0}) are CPs even though there is no overt complementizer to head the
phrase in (\ex{-1}).  Our grammar does not distinguish by category label
between the phrases that would be labeled in GB as IP and CP.  We label
both of these phrases S.  The difference between these two levels is the
presence or absence of the complementizer (or extracted WH constituent), and is
represented in our system as a difference in feature values (here, of the {\bf
$<$comp$>$} feature), and the presence of the additional structure contributed
by the complementizer or extracted constituent.  This illustrates an important
distinction in XTAG, that between features and node labels.  Because we have a
sophisticated feature system, we are able to make fine-grained distinctions
between nodes with the same label which in another system might have to be
realized by using distinguishing node labels.
 
\section{Complementizers and Embedded Clauses in English:  The
Data}
\label{data}

Verbs selecting sentential complements (or subjects) place restrictions on
their complements, in particular, on the form of the embedded verb
phrase.\footnote{Other considerations, such as the relationship between the
tense/aspect of the matrix clause and the tense/aspect of a complement clause
are also important but are not currently addressed in the current English XTAG
grammar.}  Furthermore, complementizers are constrained to appear with certain
types of clauses, again, based primarily on the form of the embedded VP.  For
example, {\it hope\/} selects both indicative and infinitival complements. With
an indicative complement, it may only have {\it that\/} or null as possible
complementizers; with an infinitival complement, it may only have a null
complementizer.  Verbs that allow wh+ complementizers, such as {\it ask}, can
take {\it whether} and {\it if} as complementizers.  The possible combinations
of complementizers and clause types is summarized in Table \ref{facts}.

As can be seen in Table \ref{facts}, sentential subjects differ from
sentential complements in requiring the complementizer {\it that\/}
for all indicative and subjunctive clauses.  In sentential complements,
{\it that\/} often varies freely with a null complementizer, as
illustrated in (\ex{1})-(\ex{6}).

\enumsentence{Christy hopes that Mike wins.}
\enumsentence{Christy hopes Mike wins.}
\enumsentence{Dania thinks that Newt is a liar.}
\enumsentence{Dania thinks Newt is a liar.}
\enumsentence{That Helms won so easily annoyed me.}
\enumsentence{$\ast$Helms won so easily annoyed me.}


\begin{table}[ht]
\centering
\begin{tabular}{|l|llllll|} \hline
Complementizer:&&that&whether&if&for&null\\
\hline
Clause type&&&&&&\\
\hline
indicative&subject&Yes&Yes&No&No&No\\
&complement&Yes&Yes&Yes&No&Yes\\
\hline
infinitive&subject&No&Yes&No&Yes&Yes\\
&complement&No&Yes&No&Yes&Yes\\
\hline
subjunctive&subject&Yes&No&No&No&No\\
&complement&Yes&No&No&No&Yes\\
\hline
gerundive\footnotemark\ &complement&No&No&No&No&Yes\\
\hline
base & complement & No & No & No & No & Yes \\
\hline
small clause & complement & No & No & No & No & Yes \\
\hline
\end{tabular}
\vspace{.2in}
\caption{Summary of Complementizer and Clause Combinations}
\label{facts}
\end{table}
\footnotetext{Most gerundive phrases are treated as NP's.  In
fact, all gerundive subjects are treated as NP's, and the only gerundive
complements which receive a sentential parse are those for which there is no
corresponding NP parse.  This was done to reduce duplication of parses. See
Chapter~\ref{gerunds-chapter} for further discussion of
gerunds.\label{gerund-footnote}}


Another fact which must be accounted for in the analysis is that in infinitival
clauses, the complementizer {\it for} must appear with an overt subject NP,
whereas a complementizer-less infinitival clause never has an overt subject, as
shown in (\ex{1})-(\ex{4}). (See section~\ref{for-complementizer} for more
discussion of the case assignment issues relating to this construction.)

\enumsentence{To lose would be awful.}
\enumsentence{For Penn to lose would be awful.}
\enumsentence{$\ast$For to lose would be awful.}
\enumsentence{$\ast$Penn to lose would be awful.}

In addition, some verbs select {\bf $<$wh$>$=+} complements (either questions
or clauses with {\it whether} or {\it if}) \cite{grimshaw90}:

\enumsentence{Jesse wondered who left.}
\enumsentence{Jesse wondered if Barry left.}
\enumsentence{Jesse wondered whether to leave.}
\enumsentence{Jesse wondered whether Barry left.}
\enumsentence{$\ast$Jesse thought who left.}
\enumsentence{$\ast$Jesse thought if Barry left.}
\enumsentence{$\ast$Jesse thought whether to leave.}
\enumsentence{$\ast$Jesse thought whether Barry left.}

\section{Features Required}
\label{s-features}

As we have seen above, clauses may be {\bf $<$wh$>$=+} or {\bf $<$wh$>$=--},
may have one of several complementizers or no complementizer, and can be of
various clause types.  The XTAG analysis uses three features to capture these
possibilities: {\bf $<$comp$>$} for the variation in complementizers,
{\bf$<$wh$>$} for the question vs.  non-question alternation and {\bf
$<$mode$>$}\footnote{{\bf $<$mode$>$} actually conflates several types of
information, in particular verb form and mood.} for clause types.  In addition
to these three features, the {\bf $<$assign-comp$>$} feature represents
complementizer requirements of the embedded verb.  More detailed discussion of
the {\bf $<$assign-comp$>$} feature appears below in the discussions of
sentential subjects and of infinitives.  The four features and their possible
values are shown in Table \ref{feat}.


\begin{table}[th]
\centering
\begin{tabular}{|l|c|} \hline
Feature&Values\\
\hline
{\bf $<$comp$>$}&that, if, whether, for, rel, nil\\
\hline
{\bf$<$mode$>$}&ind, inf, subjnt, ger, base, ppart, nom/prep\\
\hline
{\bf$<$assign-comp$>$}&that, if, whether, for, rel, ind\underline{~}nil, inf\underline{~}nil\\
\hline
{\bf$<$wh$>$}&+,--\\
\hline
\end{tabular}
\caption{Summary of Relevant Features}
\label{feat}
\end{table}


\section{Distribution of Complementizers}
\label{comp-distr}

Like other non-arguments, complementizers anchor an auxiliary tree (shown in
Figure \ref{comp-tree}) and adjoin to elementary clausal trees.  The auxiliary
tree for complementizers is the only alternative to having a complementizer
position `built into' every sentential tree.  The latter choice would mean
having an empty complementizer substitute into every matrix sentence and a
complementizerless embedded sentence to fill the substitution node.  Our choice
follows the XTAG principle that initial trees consist only of the arguments of
the anchor\footnote{See section~\ref{compl-adj} for a discussion of the
difference between complements and adjuncts in the XTAG grammar.} -- the S tree
does not contain a slot for a complementizer, and the $\beta$COMP tree has only
one argument, an S with particular features determined by the complementizer.
Complementizers select the type of clause to which they adjoin through
constraints on the {\bf $<$mode$>$} feature of the S foot node in the tree
shown in Figure~\ref{comp-tree}.  These features also pass up to the root node,
so that they are `visible' to the tree where the embedded sentence
adjoins/substitutes.

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/betaCOMPs_that_.ps,height=8.2cm}
\caption{Tree $\beta$COMPs, anchored by {\it that}}
\label{comp-tree}
\end{figure}

The grammar handles the following complementizers: {\it that\/}, {\it
whether\/}, {\it if\/}, {\it for\/}, and no complementizer, and the
clause types: indicative, infinitival, gerundive, past participial,
subjunctive and small clause ({\bf nom/prep}).  The {\bf
$<$comp$>$} feature in a clausal tree reflects the value of the
complementizer if one has adjoined to the clause. 

The {\bf $<$comp$>$} and {\bf $<$wh$>$} features receive their root
node values from the particular complementizer which anchors the tree.
The $\beta$COMPs tree adjoins to an S node with the feature {\bf
$<$comp$>$=nil}; this feature indicates that the tree does not already
{\bf have} a complementizer adjoined to it.\footnote{ Because root S's
cannot have complementizers, the parser checks that the root S has {\bf
$<$comp$>$=nil} at the end of the derivation, when the S is also checked for
a tensed verb.} We ensure that there are no stacked complementizers by
requiring the foot node of $\beta$COMPs to have {\bf $<$comp$>$=nil}.

% as well
%as using the {\bf $<$conj$>$=nil} feature to prevent complementizers from
%adjoining above subordinating conjunctions.

\section{Case assignment, {\it for\/} and the two {\it to\/}'s}
\label{for-complementizer}

The {\bf $<$assign-comp$>$} feature is used to represent the
requirements of particular types of clauses for particular
complementizers.  So while the {\bf $<$comp$>$} feature represents
constraints originating from the VP dominating the clause, the {\bf
$<$assign-comp$>$} feature represents constraints originating from the
highest VP in the clause. {\bf $<$assign-comp$>$} is used to control the
%appearance of subjects in infinitival clauses,  to
%ensure the correct distribution of complementizers in sentential
%subjects, and to block `that-trace' violations.
the appearance of subjects in infinitival clauses (see discussion of
ECM constructions in \ref{ecm-verbs}), to block bare indicative
sentential subjects (bare infinitival subjects are allowed), and to
block `that-trace' violations.

Examples (\ex{2}), (\ex{3}) and (\ex{4}) show that an accusative
case subject is obligatory in an infinitive clause if the
complementizer {\it for\/} is present. The infinitive clauses in
(\ex{1}) is analyzed in the English XTAG grammar as
having a PRO subject.  

%The apparent subject of {\it to win\/} in
%(\ex{1}) is taken to be an object of the verb rather than the subject
%of the infinitive clause. 
%\enumsentence{Mike wants her to pass the exam.}
%Note: I (Seth) took out this sentence, since the tech report 
%claims it gets an object-control analysis, while it in fact gets an
% ECM analysis.  It may be the case that it *should* get an ECM analysis,
% but for now I took it out, because it doesn't seem to have anything to
% do anyway with the point of this section.

\enumsentence{Christy wants to pass the exam.}
\enumsentence{Mike wants for her to pass the exam.}
\enumsentence{$\ast$Mike wants for she to pass the exam.}
\enumsentence{$\ast$Christy wants for to pass the exam.}
 
The {\it for-to\/} construction is particularly illustrative of the
difficulties and benefits faced in using a lexicalized grammar.  It is
commonly accepted that {\it for\/} behaves as a case-assigning
complementizer in this construction, assigning accusative case to the
`subject' of the clause since the infinitival verb does not assign
case to its subject position.  However, in our featurized grammar, the
absence of a feature licenses anything, so we must have overt null
case assigned by infinitives to ensure the correct distribution of PRO
subjects. (See section~\ref{case-assignment} for more discussion of
case assignment.)  This null case assignment clashes with accusative
case assignment if we simply add {\it for\/} as a standard
complementizer, since NP's (including PRO) are drawn from the lexicon
already marked for case.  Thus, we must use the {\bf
$<$assign-comp$>$} feature to pass information about the verb up to
the root of the embedded sentence.  To capture these facts, two
infinitive {\it to}'s are posited. One infinitive {\it to\/} has {\bf
$<$assign-case$>$=none} which forces a PRO subject, and {\bf
$<$assign-comp$>$=inf\_nil} which prevents {\it for\/} from
adjoining. The other infinitive {\it to\/} has no value at all for
{\bf $<$assign-case$>$} and has {\bf $<$assign-comp$>$=for/ecm}, so that
it can only occur either with the complementizer {\it for\/} or with
ECM constructions. In those
instances either {\it for} or the ECM verb
supplies the {\bf $<$assign-case$>$} value, assigning
 accusative case to the overt subject.
 
\section{Sentential Complements of Verbs}
\label{sent-complements}
{\bf Tree families}: Tnx0Vs1, Tnx0Vnx1s2, TItVnx1s2, TItVpnx1s2, TItVad1s2. 


Verbs that select sentential complements restrict the {\bf $<$mode$>$}
and {\bf $<$comp$>$} values for those complements. Since with very few
exceptions\footnote{For example, long distance extraction is not
possible from the S complement in it-clefts.} long distance extraction
is possible from sentential complements, the S complement nodes are
adjunction nodes. Figure \ref{think} shows the declarative tree
for sentential complements, anchored by {\it think}.  

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/think.ps,height=1.7in}
\caption{Sentential complement tree: $\beta$nx0Vs1}
\label{think}
\label{2;1,10}
\end{figure}

The need for an adjunction node rather than a substitution node at S$_{1}$ may
not be obvious until one considers the derivation of sentences with long
distance extractions.  For example, the declarative in (\ex{1}) is derived by
adjoining the tree in Figure~\ref{aard-emu}(b) to the S$_{1}$ node of the tree
in Figure~\ref{aard-emu}(a).  Since there are no bottom features on S$_{1}$,
the same final result could have been achieved with a substitution node at
S$_{1}$.

\enumsentence{The emu thinks that the aardvark smells terrible.}

\begin{figure}[htb]
\centering
\begin{tabular}{ccc}
\psfig{figure=ps/sent-comps-subjs-files/aard-smells.ps,height=2.1in}&
\hspace{0.3in}&
\psfig{figure=ps/sent-comps-subjs-files/emu-thinks.ps,height=2.1in}\\
(a)&&(b)\\
\end{tabular}
\caption{Trees for {\it The emu thinks that the aardvark smells terrible.}}  
\label{aard-emu}
\label{1;4,4}
\end{figure}

However, adjunction is crucial in deriving sentences with
long distance extraction, as in sentences (\ex{1}) and (\ex{2}).  

\enumsentence{Who does the emu think smells terrible?}
\enumsentence{Who did the elephant think the panda heard the emu say
smells terrible?} 

The example in (\ex{-1}) is derived from the trees for {\it who smells
terrible?}  shown in Figure ~\ref{who-smells} and {\it the emu thinks} S shown
in Figure~\ref{aard-emu}(b), by adjoining the latter at the S$_r$ node of the
former.\footnote{See Chapter~\ref{auxiliaries} for a discussion of do-support.}
This process is recursive, allowing sentences like (\ex{0}). Such a
representation has been shown by \cite{kj85} to be well-suited for describing
unbounded dependencies.

\begin{figure}[thb]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/who-smells.ps,height=2.3in}
\caption{Tree for {\it Who smells terrible?}}
\label{who-smells}
\label{1;4,14}
\end{figure}

In English, a complementizer may not appear on a complement with an extracted
subject (the `that-trace' configuration). This phenomenon
is illustrated in (\ex{1})-(\ex{3}):

\enumsentence{Which animal did the giraffe say that he likes?}
\enumsentence{$\ast$Which animal did the giraffe say that likes him?}
\enumsentence{Which animal did the giraffe say likes him?}

These sentences are derived in XTAG by adjoining the tree for {\it did the
giraffe say} S at the S$_r$ node of the tree for either {\it which animal likes
him} (to yield sentence~(\ex{0})) or {\it which animal he likes} (to yield
sentence~(\ex{-2})).  That-trace violations are blocked by the presence of the
feature {\bf $<$assign-comp$>$=inf\underline{~}nil/ind\underline{~}nil/ecm}
feature on the bottom of the S$_r$ node of trees with extracted subjects (W0),
i.e. those used in sentences such as (\ex{-1}) and (\ex{0}).  
If a complementizer tree, $\beta$COMPs, adjoins to a subject
extraction tree at $S_r$, its {\bf $<$assign-comp$>$ =
that/whether/for/if} feature will clash and the derivation will
fail. If there is no complementizer, there is no feature clash, and this will
permit the derivation of sentences like (\ex{0}), or of ECM constructions, in
which case the ECM verb will have {\bf $<$assign-comp$>$=ecm} (see
section~\ref{ecm-verbs} for more discussion of the ECM case).
Complementizers may adjoin normally to object extraction trees such as those
used in sentence~(\ex{-2}), and so object extraction trees have no value 
for the {\bf $<$assign-comp$>$} feature.
%This blocks (or
%`filters') any other values of {\bf $<$assign-comp$>$} projected by the verb,
%and ensures that no complementizer is able to adjoin at this node.


In the case of indirect questions, subjacency follows from the
principle that a given tree cannot contain more than one
wh-element. Extraction out of an indirect question is ruled out
because a sentence like:

\enumsentence{$\ast$ Who$_{i}$ do you wonder who$_{j}$ e$_{j}$ loves e$_{i}$ ?}

\noindent would have to be derived from the adjunction of {\it do you
wonder} into {\it who$_{i}$ who$_{j}$ e$_{j}$ loves e$_{i}$}, which is an
ill-formed elementary tree.\footnote{This does not mean that elementary trees
with more than one gap should be ruled out across the grammar. Such trees might
be required for dealing with parasitic gaps or gaps in coordinated structures.}

\subsection{Exceptional Case Marking Verbs}
\label{ecm-verbs}

{\bf Tree family}: TXnx0Vs1
Exceptional Case Marking verbs are those which assign accusative case to the
subject of the sentential complement. This is in contrast to verbs
in the Tnx0Vnx1s2 family (section~\ref{nx0Vnx1s2-family}), which assign 
accusative case to an NP which is not part of the sentential complement.  

The subject of an ECM infinitive
complement is assigned accusative case is a manner
analogous to that of a subject in a {\it for-to\/} construction, as described
in section~\ref{for-complementizer}.  As in the {\it for-to\/} case, the
ECM verb assigns accusative case into the subject of the lower infinitive, and
so the infinitive uses the {\it to} which has no value for
{\bf $<$assign-case$>$} and has {\bf $<$assign-comp$>$=for/ecm}.  The ECM verb
has {\bf $<$assign-comp$>$=ecm} and {\bf $<$assign-case$>$=acc} on its
foot.  The former allows the {\bf $<$assign-comp$>$} features of the ECM
verb and the {\it to} tree to unify, and so be used together, and the latter
assigns the accusative case to the lower subject.  

Figure~\ref{expects-decl} shows the 
declarative tree for the 
tree for the TXnx0Vs1 family, in this case anchored by {\it expects}.
Figure~\ref{van-expects} shows a parse for {\it Van expects Bob to talk}

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/expects.ps,height=3.3in}
\caption{ECM tree: $\beta$Xnx0Vs1}
\label{expects-decl}
\label{3;1,15}
\end{figure}

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/van-expects.ps,height=3.3in}
\caption{Sample ECM parse}
\label{van-expects}
\end{figure}

The ECM and {\it for-to\/} cases are analogous in how they are used together
with the correct infinitival {\it to} to assign accusative case to the 
subject of the lower infinitive.  However, they are different in that
{\it for} is blocked along with other complementizers in subject extraction
contexts, as discussed in section~\ref{sent-complements}, as in
(\ex{1}), while subject extraction is compatible with ECM cases, 
as in (\ex{2}).

\enumsentence{$\ast$What child did the giraffe ask for to leave?}
\enumsentence{Who did Bill expect to eat beans?}

Sentence (\ex{-1}) is ruled out by the {\bf $<$assign-comp$>$=
inf\underline{~}nil/ind\underline{~}nil/ecm} feature
on the subject extraction tree for {\it ask}, since the
{\bf $<$assign-comp$>$=for} feature from the {\it for} tree will fail to 
unify.  However, 
(\ex{0}) will be allowed since {\bf $<$assign-comp$>$=ecm} feature on the
{\it expect} tree will unify with the foot of the ECM verb tree.  
The use of features allows the ECM and
{\it for-to\/} constructions to act the same for exceptional case assignment,
while also being distinguished for that-trace violations.

Verbs that take bare infinitives, as in (\ex{1}), are 
also treated as ECM verbs,
the only difference being that their foot feature has
{\bf $<$mode$>$=base} instead of {\bf $<$mode$>$=inf}.  Since the complement
does not have {\it to}, there is no question of using the {\it to} tree
for allowing accusative case to be assigned.  Instead, verbs with
{\bf $<$mode$>$=base} allow either accusative or nominative case to be 
assigned to the subject, and the foot of the ECM bare infinitive tree 
forces it to be accusative by its {\bf $<$assign-case$>$=acc} value at its
foot node unifies with the {\bf $<$assign-case$>$=nom/acc} value of the 
bare infinitive clause.

\enumsentence{Bob sees the harmonica fall.}


The passive for the ECM verbs is treated as a raising verb.
Since the
subject of the infinitive is not thematically selected by the ECM verb,
it is not part of the ECM verb's tree, and so it cannot be part of the
passive tree. Therefore, the passive acts as a raising verb, and so for
example, 
the sentence {\it John is believed to be happy} would be derived by
adjoining {\it believed} in as a raising verb.  For
further discussion, see section~\ref{sm-clause-xtag-ECM}.

\section{Sentential Subjects}
\label{sent-subjs}

{\bf Tree families}: Ts0Vnx1, Ts0Ax1, Ts0N1, Ts0Pnx1, Ts0ARBPnx1, 
Ts0PPnx1, Ts0PNaPnx1, Ts0V, Ts0Vtonx1, Ts0NPnx1, Ts0APnx1, Ts0A1s1.

Verbs that select sentential subjects anchor trees that have an S node
in the subject position rather than an NP node.  Since extraction is
not possible from sentential subjects, they are implemented as
substitution nodes in the English XTAG grammar.  Restrictions on
sentential subjects, such as the required {\it that} complementizer for
indicatives, are enforced by feature values specified on the S
substitution node in the elementary tree.  

Sentential subjects behave essentially like sentential complements, with a few
exceptions.  In general, all verbs which license sentential subjects license
the same set of clause types. Thus, unlike sentential complement verbs which
select particular complementizers and clause types, the matrix verbs licensing
sentential subjects merely license the S argument. Information about the
complementizer or embedded verb is located in the tree features, rather than in
the features of each verb selecting that tree.  Thus, all sentential subject
trees have the same {\bf $<$mode$>$}, {\bf $<$comp$>$} and {\bf
$<$assign-comp$>$} values shown in Figure~\ref{comparison}(a).

\begin{figure}[htb]
\centering
\begin{tabular}{ccc}
\psfig{figure=ps/sent-comps-subjs-files/perplexes-feats.ps,height=2.2in}&
\hspace{0.5in}&
\psfig{figure=ps/sent-comps-subjs-files/think-feats.ps,height=2.6in}\\
(a)&&(b)\\
\end{tabular}
\caption{Comparison of {\bf $<$assign-comp$>$} values for sentential
subjects: $\alpha$s0Vnx1 (a) and sentential complements: $\beta$nx0Vs1 (b)}
\label{comparison}
\label{1;1,16}
\end{figure}

The major difference in clause types licensed by S-subjs and S-comps is that
indicative S-subjs obligatorily have a complementizer (see examples in
section~\ref{data}). The {\bf $<$assign-comp$>$} feature is used here to
license a null complementizer for infinitival but not indicative clauses. {\bf
$<$assign-comp$>$} has the same possible values as {\bf $<$comp$>$}, with the
exception that the {\bf nil} value is `split' into {\bf ind\_nil} and {\bf
inf\_nil}.  This difference in feature values is illustrated in
Figure~\ref{comparison}.
%This allows us to specify precisely which environments license null
%complementizers. 
%Intuitively, {\bf $<$assign-comp$>$} passes information about what
%complementizers are licensed from the verb \underline{up} to its root,
%where it is `visible' to the extra-clausal environment.  

Another minor difference is that {\it whether\/} but not {\it if\/} is
grammatical with S-subjs.\footnote{Some speakers also find {\it if\/}
  as a complementizer only marginally grammatical in S-comps.} Thus,
{\it if} is not among the {\bf $<$comp$>$} values allowed in S-subjs.
The final difference from S-comps is that there are no S-subjs with
{\bf $<$mode$>$=ger}. As noted in footnote~\ref{gerund-footnote} of
this chapter, gerundive complements are only allowed when there is no
corresponding NP parse. In the case of gerundive S-subjs, there is
always an NP parse available.

\section{Nouns and Prepositions taking Sentential Complements}
\label{NPA}

{\bf Trees}: $\alpha$NXNs, $\beta$vxPs, $\beta$Pss, $\beta$nxPs,
Tnx0N1s1, Tnx0A1s1.

\begin{figure}[thb]
\centering
\begin{tabular}{ccc}
\psfig{figure=ps/sent-comps-subjs-files/betaPss.ps,height=5.6cm}&
\hspace{0.3in}&
\psfig{figure=ps/sent-comps-subjs-files/alphaNXNs.ps,height=4cm}
\\
(a) && (b)\\
\end{tabular}
\caption{Sample trees for preposition: $\beta$Pss (a) and noun: $\alpha$NXNs (b) taking
sentential complements}
\label{nounprep}
\end{figure}

Prepositions and nouns can also select sentential complements, using
the trees listed above.  These trees use the {\bf $<$mode$>$} and {\bf
$<$comp$>$} features as shown in Figure~\ref{nounprep}.  For example,
the noun {\it claim} takes only indicative complements with {\it
that}, while the preposition {\it with} takes small clause
complements, as seen in sentences (\ex{1})-(\ex{4}).

\enumsentence{Beth's claim that Clove was a smart dog....}
\enumsentence{$\ast$Beth's claim that Clove a smart dog....}
\enumsentence{Dania wasn't getting any sleep with Doug sick.}
\enumsentence{$\ast$Dania wasn't getting any sleep with Doug was sick.}

%%Comparative adjs also take s-comps, e.g. the boys easiest to teach.
%%See Quirk, section 7.20 and others.


\section{PRO control}
\label{PRO-control}

\subsection{Types of control}

In the literature on control, two types are often distinguished: obligatory
control, as in sentences~(\ex{1}), (\ex{2}), (\ex{3}), and (\ex{4}) and optional 
control, as in sentence~(\ex{5}).

\enumsentence{Srini$_i$ promised Mickey$_{i}$ [PRO$_i$ to leave].}
\enumsentence{Srini persuaded Mickey$_{i}$ [PRO$_i$ to leave].}
\enumsentence{Srini$_{i}$ wanted [PRO$_i$ to leave].}
\enumsentence{Christy$_{i}$ left the party early [PRO$_i$ to go to the airport].}
\enumsentence{[PRO$_{arb/i}$ to dance] is important for Bill$_{i}$.}

At present, an analysis for obligatory control into complement clauses
(as in sentences~(\ex{-4}), (\ex{-3}), and (\ex{-2})) has been implemented. An
analysis for cases of obligatory control into adjunct clauses and optional
control exists and can be found in \cite{bhatt94}.

\subsection{A feature-based analysis of PRO control}
The analysis for obligatory control involves co-indexation of the control feature
of the NP anchored by PRO to the control feature of the controller.
A feature equation in the tree anchored by the control verb 
co-indexes the control feature of the controlling NP with the foot
node of the tree.  All sentential trees have a co-indexed
control feature from the root S to the subject NP. 

When the tree containing the controller adjoins
onto the complement clause tree containing the PRO, 
the features of the foot node of the
auxiliary tree are unified with the bottom features of the root node of the 
complement clause
tree containing the PRO. This leads to the control feature of the controller
being co-indexed with the control feature of the PRO.

Depending on the choice of the controlling verb, the control
propagation paths in the auxiliary trees are different.  In the case of subject
control (as in sentence~(\ex{-3})), the subject NP and the foot node are
have co-indexed control features, while for object control
(e.g. sentence~(\ex{-4}), the object NP and the foot node are 
co-indexed for control. Among verbs that belong to the Tnx0Vnx1s2 family,
i.e. verbs that take an NP object and a clausal complement, subject-control
verbs form a distinct minority, {\em promise} being the only commonly used
verb in this class.


Consider the derivation of sentence~(\ex{-3}). The auxiliary tree for
{\em persuade}, shown in Figure \ref{persuade-tree}, has the following
feature equation~(\ex{1}).
\enumsentence{  NP$_{1}$:{\bf $<$control$>$} = S$_{2}$.t:{\bf $<$control$>$} }
The auxiliary tree adjoins into the tree for {\em leave}, shown in
Figure \ref{leave-tree}, which 
has the following feature equation~(\ex{1}).
\enumsentence{S$_{r}$.b:{\bf $<$control$>$} = NP$_{0}$.t:{\bf $<$control$>$}}
Since the adjunction takes place at the root node (S$_{r}$) of the
{\em leave} tree, after unification, NP$_{1}$ of the {\em persuade}
tree and NP$_{0}$ of the {\em leave} tree share a control feature. The
resulting derived and derivation trees are shown in Figures
\ref{derived-tree} and \ref{derivation-tree}.

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/betanx0Vnx1s2_persuaded_.ps,height=5.2cm}
\caption{Tree for {\it persuaded}}
\label{persuade-tree}
\end{figure}

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/alphanx0V_leave_.ps,height=5.2cm}
\caption{Tree for {\it leave}}
\label{leave-tree}
\end{figure}

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/persuaded-derv.ps,height=8.2cm}
\caption{Derived tree for {\it Srini persuaded Mickey to leave}}
\label{derived-tree}
\end{figure}

\begin{figure}[hbt]
\centering
\hspace{0.0in}
\psfig{figure=ps/sent-comps-subjs-files/persuaded-derivation.ps,height=4.2cm}
\caption{Derivation tree for {\it Srini persuaded Mickey to leave}}
\label{derivation-tree}
\end{figure}


\subsection{The nature of the control feature}
The control feature does not have any value and is used only for
co-indexing purposes. If two NPs have their control features
co-indexed, it means that they are participating in a relationship
of control; the c-commanding NP controls the c-commanded NP. 

\subsection{Long-distance transmission of control features}
Cases involving embedded infinitival complements with PRO subjects such as
(\ex{1}) can also be handled.

\enumsentence{ John$_i$ wants [PRO$_i$ to want [PRO$_i$ to dance]].}

The control feature of `John' and the two PRO's all get co-indexed.
This treatment might appear to lead to a problem. Consider (\ex{1}):

\enumsentence{ John$_{*i}$ wants [Mary$_i$ to want [PRO$_i$ to dance]].}

If both the `want' trees have the control feature of their subject
co-indexed to their foot nodes, we would have a situtation where
the PRO is co-indexed for control feature with `John', as well as with `Mary'. 
Note that the higher `want' in (\ex{-1}) is {\em want$_{ECM}$} 
- it assigns case
to the subject of the lower clause while the lower `want' in (\ex{-1}) is 
not. Subject control is restricted
to non-ECM (Exceptional Case Marking) verbs that take infinitival 
complements. Since the two `want's in (\ex{-1}) are different with
respect to their control (and other) properties, the control feature
of PRO stops at `Mary' and is not transmitted to the higher clause.


\subsection{Locality constraints on control}
PRO control obeys locality constraints. The controller for PRO has to be
in the immediately higher clause. Consider the ungrammatical sentence~(\ex{1})
((\ex{1}) is ungrammatical only with the co-indexing indicated below).
\enumsentence{* John$_i$ wants [PRO$_i$ to persuade Mary$_i$ [PRO$_i$ to dance]]}
However, such a derivation is ruled out automatically by the 
mechanisms of a TAG derivation and feature unification. 
Suppose it was possible to first compose the {\em want} tree with the
{\em dance} tree and then insert the {\em persuade} tree. (This is not
possible in the XTAG grammar because of the convention that
auxiliary trees have NA (Null Adjunction) constraints on their foot nodes.)
Even then, at the end of the derivation the control feature of the 
subject of {\em want} would end up co-indexed with the PRO subject of
{\em persuade} and the control feature of {\em Mary} would be co-indexed with the
PRO subject of {\em dance} as desired. There is no way to generate the illegal
co-indexing in (\ex{-1}). Thus the locality constraints on PRO control 
fall out from the mechanics of TAG derivation and feature unification. 



\section{Reported speech}

Reported speech is handled in the XTAG grammar by having the reporting
clause adjoin into the quote. Thus, the reporting clause is an
auxiliary tree, anchored by the reporting verb. See \cite{doran-diss}
for details of the analysis. There are trees in both the Tnx0Vs1 and
Tnx0nx1s2 families to handle reporting clauses which precede, follow
and come in the middle of the quote.

