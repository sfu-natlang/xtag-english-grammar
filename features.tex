\chapter{Features}
\label{features}

Table~\ref{feature-table} contains a comprehensive list of the features in the
XTAG grammar and their possible values.

The table is followed by short `biographical' sketches of the various features
currently in use in the Xtag English grammar.

\footnotesize
\begin{table}[hbt]
\centering
\begin{tabular}{|l|l|}
\hline
Feature&Value\\
\hline
\hline
$<$agr 3rdsing$>$&$+,-$\\
$<$agr num$>$&plur,sing\\
$<$agr pers$>$&1,2,3\\
$<$agr gen$>$&fem,masc,neuter\\
$<$assign-case$>$&nom,acc,none\\
$<$assign-comp$>$&that,whether,if,for,ecm,rel,inf\_nil,ind\_nil,ppart\_nil,none\\
$<$card$>$&$+,-$\\
$<$case$>$&nom,acc,gen,none\\
$<$comp$>$&that,whether,if,for,rel,inf\_nil,ind\_nil,nil\\
$<$compar$>$&$+,-$\\
$<$compl$>$&$+,-$\\
$<$conj$>$&and,or,but,comma,scolon,to,nil\\
$<$const$>$&$+,-$\\
$<$contr$>$&$+,-$\\
$<$control$>$&no value, indexing only\\
$<$decreas$>$&$+,-$\\
$<$definite$>$&$+,-$\\
$<$disc-conj$>$&$+, -$\\
$<$displ-const$>$&$+,-$\\
$<$equiv$>$&$+,-$\\
$<$extracted$>$&$+,-$\\
$<$gen$>$&$+,-$\\
$<$inv$>$&$+,-$\\
$<$invlink$>$&no value, indexing only\\
$<$mainv$>$&$+,-$\\
$<$mode$>$&base,ger,ind,inf,imp,nom,ppart,prep,sbjunt\\
$<$neg$>$&$+,-$\\
$<$passive$>$&$+,-$\\
$<$pred$>$&$+,-$\\
$<$pron$>$&$+,-$\\
$<$punct bal$>$&dquote,squote,paren,nil\\
$<$punct contains dquote$>$&$+,-$\\
$<$punct contains squote$>$&$+,-$\\
$<$punct struct$>$&comma,dash,colon,scolon,none,nil\\
$<$punct term$>$&per,qmark,excl,none,nil\\
$<$quan$>$&$+,-$\\
$<$rel-clause$>$&$+,-$\\
$<$rel-pron$>$&ppart,ger,adj-clause\\
$<$select-mode$>$&ind,inf,ppart,ger\\
$<$sub-conj$>$&ind1,ind2,ind3,inf1,inf2,ger,nil\\
$<$super$>$&$+,-$\\
$<$tense$>$&pres,past\\
$<$trace$>$&no value, indexing only\\
$<$trans$>$&$+,-$\\
$<$weak$>$&$+,-$\\
$<$wh$>$&$+,-$\\
\hline
\end{tabular}
\caption{List of features and their possible values}
\label{feature-table}
\end{table}

\normalsize


\section{Agreement}
{\bf $\langle$agr$\rangle$} is a complex feature.
It can have as its subfeatures:\\
{\bf $\langle$agr 3rdsing$\rangle$}, possible values: {\bf $+/-$ }\\
{\bf $\langle$agr num$\rangle$}, possible values: {\bf $plur,sing$ }\\
{\bf $\langle$agr pers$\rangle$}, possible values: {\bf $1,2,3$ }\\
{\bf $\langle$agr gen$\rangle$}, possible values: {\bf $masc,fem,neut$ }

These features are used to ensure agreement between a verb and its subject.

Where does it occur:\\ Nouns comes specified from the lexicon with
their {\bf $\langle$agr$\rangle$} features. e.g. {\em books} is {\bf
$\langle$agr 3rdsing$\rangle$:~--}, {\bf $\langle$agr num$\rangle$:~plur}, and {\bf $\langle$agr pers$\rangle$:~3}. Only pronouns use the
{\bf $<$gen$>$} (gender) feature.

The {\bf $\langle$agr$\rangle$} features of a noun are transmitted up the 
NP tree by the following equation:\\
{\bf NP.b:$\langle$agr$\rangle =$ N.t:$\langle$agr$\rangle$}

Agreement between a verb and its subject is mediated by the following feature
equations:

\enumsentence{ {\bf NP$_{subj}$:$\langle$agr$\rangle =$ VP.t:$\langle$agr$\rangle$}}


\enumsentence{ {\bf VP.b:$\langle$agr$\rangle =$ V.t:$\langle$agr$\rangle$}}

Agreement has to be done as a two step process because whether the
verb agrees with the subject or not depends upon whether some auxiliary verb
adjoins in and upon what the {\bf $\langle$agr$\rangle$} specification of 
the verb is. 

Verbs also come specified from the lexicon with their {\bf
$\langle$agr$\rangle$} features, e.g. the {\bf $\langle$agr$\rangle$}
features of the verb {\em sings} are {\bf $\langle$agr
3rdsing$\rangle$:~+}, {\bf $\langle$agr num$\rangle$:~sing}, and {\bf
$\langle$agr pers$\rangle$:~3}; Non-finite forms of the verb {\em
sing} e.g. {\em singing} do not come with an {\bf
$\langle$agr$\rangle$} feature specification.

\subsection{Agreement and Movement}
The {\bf $\langle$agr$\rangle$} features of a moved NP and its trace 
are co-indexed. This captures the fact that movement does not disrupt 
a pre-existing agreement relationship between an NP and a verb.

\enumsentence{ \ [Which boys]$_{i}$ does John think [t$_{i}$ are/*is intelligent]?}



\section{Case}

There are two features responsible for case-assignment:\\
{\bf $\langle$case$\rangle$}, possible values: {\bf nom, acc, gen, none}\\
{\bf $\langle$assign-case$\rangle$}, possible values: {\bf nom, acc, none}

Case assigners (prepositions and verbs) as well as the VP, S and PP
nodes that dominate them have an {\bf $\langle$assign-case$\rangle$}
case feature. Phrases and lexical items that have case i.e. Ns and NPs
have a {\bf $\langle$case$\rangle$} feature.

Case assignment by prepositions involves the following equations:

\enumsentence{ {\bf PP.b:$\langle$assign-case$\rangle =$ P.t:$\langle$case$\rangle$}}


\enumsentence{ {\bf NP.t:$\langle$case$\rangle =$ P.t:$\langle$case$\rangle$}}

Prepositions come specified from the lexicon with their {\bf $\langle$assign-case$\rangle$}
feature.

\enumsentence{ {\bf P.b:$\langle$assign-case$\rangle =$ acc}}


Case assignment by verbs has two parts: assignment of case to the
object(s) and assignment of case to the subject. Assignment of case to
the object is simpler.  English verbs always assign accusative case to
their NP objects (direct or indirect).  Hence this is built into the
tree and not put into the lexical entry of each individual verb.

\enumsentence{ {\bf NP$_{object}$.t:$\langle$case$\rangle =$ acc}}

Assignment of case to the subject involves the following two equations.

\enumsentence{ {\bf NP$_{subj}$:$\langle$case$\rangle =$ VP.t:$\langle$assign-case$\rangle$}}


\enumsentence{ {\bf VP.b:$\langle$assign-case$\rangle =$ V.t:$\langle$assign-case$\rangle$}}

This is a two step process -- the final case assigned to the subject
depends upon the {\bf $\langle$assign-case$\rangle$} feature of the
verb as well as whether an auxiliary verb adjoins in.

Finite verbs like {\em sings} have {\bf nom} as the value of their
{\bf $\langle$assign-case$\rangle$} feature. Non-finite verbs have
{\bf none} as the value of their {\bf $\langle$assign-case$\rangle$}
feature. So if no auxiliary adjoins in, the only subject they can have
is {\bf PRO} which is the only NP with {\bf none} as the value its
{\bf $\langle$case$\rangle$} feature.

\subsection{ECM}
Certain verbs e.g. {\em want, believe, consider} etc. and one complementizer
{\em for} are able to assign case to the subject of their complement clause. 

The complementizer {\em for}, like the preposition {\em for}, has the
{\bf $\langle$assign-case$\rangle$} feature of its complement set to
{\bf acc}. Since the {\bf $\langle$assign-case$\rangle$} feature of
the root S$_{r}$ of the complement tree and the {\bf
$\langle$case$\rangle$} feature of its NP subject are co-indexed, this
leads to the subject being assigned accusative case.

ECM verbs have the {\bf $\langle$assign-case$\rangle$}  feature of their
foot S node set to {\bf acc}. The co-indexation between the 
{\bf $\langle$assign-case$\rangle$} feature of
the root S$_{r}$ and the {\bf $\langle$case$\rangle$} feature of the NP subject
leads to the subject being assigned accusative case.

\subsection{Agreement and Case}
The {\bf $\langle$case$\rangle$} features of a moved NP and its trace 
are co-indexed. This captures the fact that movement does not disrupt 
a pre-existing relationship of case-assignment between a verb and an NP.

\enumsentence{ Her$_{i}$/*She$_{i}$, I think that Odo like t$_{i}$.}


\section{Extraction and Inversion}
{\bf $\langle$extracted$\rangle$}, possible vales are {\bf $+/-$}

All sentential trees with extracted components, with the exception of
relative clauses are marked {\bf S.b$\langle$extracted$\rangle = +$}
at their top S node. The extracted element may be a {\em wh}-NP or a
topicalized NP. The {\bf $\langle$extracted$\rangle$} feature 
is currently used to block embedded topicalizations as exemplified
by the following example.
\enumsentence{ * John wants [Bill$_{i}$ [PRO to leave t$_{i}$]] }

{\bf $\langle$trace$\rangle$}: this feature is not assigned any value and
is used to co-index moved NPs and their traces which are marked by
$\epsilon$.

{\bf $\langle$wh$\rangle$}: possible values are {\bf $+/-$}\\ NPs like
{\em who}, {\em what} etc. come marked from the lexicon with a value
of {\bf $+$} for the feature {\bf $\langle$wh$\rangle$}.  Non {\em
wh}-NPs have {\bf $-$} as the value of their {\bf
$\langle$wh$\rangle$} feature. Note that {\bf $\langle$wh$\rangle$ = +
} NPs are not restricted to occurring in extracted positions, to allow
for the correct treatment of echo questions.

The {\bf $\langle$wh$\rangle$} feature is propagated up by possessives
-- e.g. the $+$ {\bf $\langle$wh$\rangle$} feature of the determiner
{\em which} in {\em which boy} is propagated up to the level of the NP
so that the value of the {\bf $\langle$wh$\rangle$} feature of the
entire NP is $+${\bf $\langle$wh$\rangle$}. This process is recursive
e.g. {\em which boy's mother}, {\em which boy's mother's sister}.

The {\bf $\langle$wh$\rangle$} feature
is also propagated up PPs. Thus the PP {\em to whom} has $+$ as the value of its 
{\bf $\langle$wh$\rangle$} feature. 

In trees with extracted NPs, the {\bf $\langle$wh$\rangle$} feature of the
root node S node is equated with the {\bf $\langle$wh$\rangle$} feature
of the extracted NPs. 

The {\bf $\langle$wh$\rangle$} feature is used to impose
subcategorizational constraints.
Certain verbs like {\em wonder} can
only take interrogative complements, other verbs such as {\em know}
can take both interrogative and non-interrogative complements, and yet
other verbs like {\em think} can only take non-interrogative
complements (cf. the {\bf $\langle$extracted$\rangle$} and {\bf
$\langle$mode$\rangle$} features also play a role in imposing 
subcategorizational constraints).

The {\bf $\langle$wh$\rangle$} feature is also used to get the correct
inversion patterns.


\subsection{Inversion, Part 1}
The following three features are used to ensure the correct pattern of
inversion:\\
{\bf $\langle$wh$\rangle$}: possible values are {\bf $+/-$}\\
{\bf $\langle$inv$\rangle$}: possible values are {\bf $+/-$}\\
{\bf $\langle$invlink$\rangle$}: possible values are {\bf $+/-$}

Facts to be captured:\\
1. No inversion with topicalization\\
2. No inversion with matrix extracted subject {\em wh}-questions\\
3. Inversion with matrix extracted object {\em wh}-questions\\
4. Inversion with all matrix {\em wh}-questions involving extraction from an
embedded clause\\
5. No inversion in embedded questions \\
6. No matrix subject topicalizations.

Consider a tree with object extraction, where NP is extracted. 
The following feature equations are used:\\

\enumsentence{ {\bf S$_{q}$.b:$\langle$wh$\rangle =$ NP.t:$\langle$wh$\rangle$}\label{inv1}}
\enumsentence{ {\bf S$_{q}$.b:$\langle$invlink$\rangle =$  S$_{q}$.b:$\langle$inv$\rangle$}\label{inv2}}
\enumsentence{ {\bf S$_{q}$.b:$\langle$inv$\rangle =$  S$_{r}$.t:$\langle$inv$\rangle$}\label{inv3}}
\enumsentence{ {\bf S$_{r}$.b:$\langle$inv$\rangle = -$}\label{inv4}}

{\bf Root restriction}: A restriction is imposed on the final root
node of any XTAG derivation of a tensed sentence which equates the
{\bf $\langle$wh$\rangle$} feature and the {\bf
$\langle$invlink$\rangle$} feature of the final root node.

If the extracted NP is not a {\em wh}-word i.e. its {\bf
$\langle$wh$\rangle$} feature has the value $-$, at the end of the
derivation, {\bf S$_{q}$.b:$\langle$wh$\rangle$} will also have the
value $-$. Because of the root constraint {\bf
S$_{q}$.b:$\langle$wh$\rangle$} will be equated to {\bf
S$_{q}$.b:$\langle$invlink$\rangle$} which will also come to have the
value $-$. Then, by (\ref{inv3}), {\bf
S$_{r}$.t:$\langle$inv$\rangle$} will acquire the value $-$. This will
unify with {\bf S$_{r}$.b:$\langle$inv$\rangle$} which has the value
$-$ (cf. \ref{inv4}). Consequently, no auxiliary verb adjunction will
be forced. Hence, there will never be inversion in topicalization.

If the extracted NP is a {\em wh}-word i.e. its {\bf $\langle$wh$\rangle$} 
feature has the value $+$, at the end of the derivation, 
{\bf S$_{q}$.b:$\langle$wh$\rangle$} will also have the value $+$. Because of
the root constraint {\bf S$_{q}$.b:$\langle$wh$\rangle$} will be equated 
to {\bf S$_{q}$.b:$\langle$invlink$\rangle$} which will also come to have
the value $+$. Then, by (\ref{inv3}), {\bf S$_{r}$.t:$\langle$inv$\rangle$} 
will acquire the value $+$. This will not unify with {\bf S$_{r}$.b:$\langle$inv$\rangle$}
which has the value $+$ (cf. \ref{inv4}). Consequently, the adjunction
of an inverted auxiliary verb is required for the derivation to succeed.

Inversion will still take place even if the extraction is from an embedded
clause.

\enumsentence{ Who$_{i}$ does Loida think [Miguel likes t$_{i}$]}

This is because the adjoined tree's root node will also have its 
{\bf S$_{r}$.b:$\langle$inv$\rangle$} set to $-$. 


Note that inversion is only forced upon us because S$_{q}$ is the
final root node and the {\bf Root restriction} applies. In embedded
environments, the root restriction would not apply and the feature
clash that forces adjunction would not take place.

The {\bf $\langle$invlink$\rangle$} feature is not present in subject
extractions.  Consequently there is no inversion in subject questions.

Subject topicalizations are blocked by setting the 
{\bf $\langle$wh$\rangle$} feature of the extracted NP to $+$ i.e. only
{\em wh}-phrases can go in this location. 

\subsection{Inversion, Part 2}

{\bf $\langle$displ-const$\rangle$}:\\ Possible values: {\bf [set1:
+], [set1: --]}\\ In the previous section, we saw how inversion is
triggered using the {\bf $\langle$invlink$\rangle$}, {\bf
$\langle$inv$\rangle$}, {\bf $\langle$wh$\rangle$} features. Inversion
involves movement of the verb from V to C. This movement process is
represented using the {\bf $\langle$displ-const$\rangle$} feature
which is used to simulate Multi-Component TAGs.\footnote{The {\bf
$\langle$displ-const$\rangle$} feature is also used in the ECM
analysis.} The sub-value {\bf set1} indicates the inversion
multi-component set; while there are not currently any other uses of
this mechanism, it could be expanded with other sets receiving
different {\bf set} values.

The {\bf $\langle$displ-const$\rangle$} feature is used to ensure
adjunction of two trees, which in this case are the auxiliary
tree corresponding to the moved verb (S adjunct) and the auxiliary tree
corresponding to the trace of the moved verb (VP adjunct). The following
equations are used:

\enumsentence{  {\bf S$_{r}$.b:$\langle$displ-const set1$\rangle = -$}\label{dis1}}
\enumsentence{  {\bf S.t:$\langle$displ-const set1$\rangle = +$}\label{dis2}}
\enumsentence{  {\bf VP.b:$\langle$displ-const set1$\rangle =$
          V.t:$\langle$displ-const set1$\rangle$}\label{dis3}}
\enumsentence{  {\bf V.b:$\langle$displ-const set1$\rangle = +$}\label{dis4}}
\enumsentence{  {\bf S$_{r}$.b:$\langle$displ-const set1$\rangle =$ 
          VP.t:$\langle$displ-const set1$\rangle$}\label{dis5}}


\section{Clause Type}
There are several features that mark clause type.\footnote{We have
already seen one instance of a feature that marks clause-type: {\bf
$\langle$extracted$\rangle$}, which marks whether a certain S involves
extraction or not.} They are:\\ {\bf $\langle$mode$\rangle$}\\ {\bf
$\langle$passive$\rangle$}: possible values are {\bf +/--}


{\bf $\langle$mode$\rangle$}: possible values are 
{\bf base, ger, ind, inf, imp, nom, ppart, prep, sbjnct}\\
The {\bf $\langle$mode$\rangle$} feature of a verb in its root form is
{\bf base}. The {\bf $\langle$mode$\rangle$} feature of a verb in its past 
participial form is {\bf ppart}, the {\bf $\langle$mode$\rangle$} feature of a 
verb in its progressive/gerundive form is {\bf ger}, 
the {\bf $\langle$mode$\rangle$} feature of a tensed verb is {\bf ind},
and the {\bf $\langle$mode$\rangle$} feature of a verb in the imperative 
is {\bf imp}. 

{\bf nom} is the {\bf $\langle$mode$\rangle$} value of AP/NP
predicative trees headed by a null copula.  {\bf prep} is the {\bf
$\langle$mode$\rangle$} value of PP predicative trees headed by a null
copula.  Only the copula auxiliary tree, some sentential complement
verbs (such as {\it consider} and raising verb auxiliary trees have
{\bf nom/prep} as the {\bf $\langle$mode$\rangle$} feature
specification of their foot node. This allow them, and only them, to
adjoin onto AP/NP/PP predicative trees with null copulas.

\subsection{Auxiliary Selection}
The {\bf $\langle$mode$\rangle$} feature is also used to state the
subcategorizational constraints between an auxiliary verb and its
complement. We model the following constraints:\\
{\em have} takes past participial complements\\
passive {\em be} takes past participial complements\\
active {\em be} takes progressive complements\\
modal verbs, {\em do}, and {\em to} take VPs headed by verbs in their
base form as their complements. 

An auxiliary verb transmits its own mode to its root and imposes its
subcategorizational restrictions on its complement i.e. on its foot node.
e.g. the auxiliary {\em have} in its infinitival form involves the
following equations:

\enumsentence{ {\bf VP$_{r}$.b:$\langle$mode$\rangle =$ 
          V.t:$\langle$mode$\rangle$}\label{mode1}}
\enumsentence{ {\bf  V.t:$\langle$mode$\rangle =$ base}\label{mode2}}
\enumsentence{ {\bf VP.b:$\langle$mode$\rangle =$ ppart}\label{mode3}}


{\bf $\langle$passive$\rangle$}: This feature is used to ensure that
passives only have {\em be} as their auxiliary. Passive trees start
out with their {\bf $\langle$passive$\rangle$} feature as {\bf +}.
This feature starts out at the level of the verb and is percolated up
to the level of the VP. This ensures that only auxiliary verbs whose
foot node has {\bf +} as their {\bf $\langle$passive$\rangle$} feature
can adjoin on a passive. Passive trees have {\bf ppart} as the value
of their {\bf $\langle$mode$\rangle$} feature. So the only auxiliary
trees that we really have to worry about blocking are trees whose foot
nodes have {\bf ppart} as the value of their {\bf
$\langle$mode$\rangle$} feature. There are two such trees -- the {\em
be} tree and the {\em have} tree. The {\em be} tree is fine because
its foot node has {\bf +} as its {\bf $\langle$passive$\rangle$}
feature, so both the {\bf $\langle$passive$\rangle$} and {\bf
$\langle$mode$\rangle$} values unify; the {\em have} tree is blocked
because its foot node has {\bf --} as its {\bf
$\langle$passive$\rangle$} feature.

\section{Relative Clauses}
Features that are peculiar to the relative clause system are:\\
{\bf $\langle$select-mode$\rangle$}, possible values are {\bf ind, inf, ppart, ger}\\
{\bf $\langle$rel-pron$\rangle$}, possible values are {\bf ppart, ger, adj-clause}\\
{\bf $\langle$rel-clause$\rangle$}, possible values are {\bf +/--}

{\bf $\langle$select-mode$\rangle$}:\\
Comps are lexically specified for {\bf $\langle$select-mode$\rangle$}.
In addition, the {\bf $\langle$select-mode$\rangle$} feature of a Comp
is equated to the {\bf $\langle$mode$\rangle$} feature of its
sister S node by the following equation:

\enumsentence{ {\bf Comp.t:$\langle$select-mode$\rangle =$ S$_{t}$.t:$\langle$mode$\rangle$}}


The lexical specifications of the Comps are shown below:
\begin{itemize}
\item $\epsilon$$_{C}$, {\bf Comp.t:$\langle$select-mode$\rangle
=$ind/inf/ger/ppart}
\item {\em that}, {\bf Comp.t:$\langle$select-mode$\rangle =$ind}
\item {\em for}, {\bf Comp.t:$\langle$select-mode$\rangle =$inf}
\end{itemize}

{\bf $\langle$rel-pron$\rangle$}:\\
There are additional constraints on where the null Comp $\epsilon$$_{C}$
can occur. The null Comp is not permitted in cases of subject
extraction unless there is an intervening clause or or
the relative clause is a reduced relative ({\bf mode = ppart/ger}).

To model this paradigm, the feature {\bf $\langle$rel-pron$\rangle$} is used in
conjunction with the following equations.


\enumsentence{
{\bf S$_{r}$.t:$\langle$rel-pron$\rangle =$ Comp.t:$\langle$rel-pron$\rangle$}}
\enumsentence{
{\bf S$_{r}$.b:$\langle$rel-pron$\rangle =$ S$_{r}$.b:$\langle$mode$\rangle$}}
\enumsentence{
{\bf Comp.b:$\langle$rel-pron$\rangle =$ppart/ger/adj-clause}
(for $\epsilon$$_{C}$)}

The full set of the equations above is only present in Comp
substitution trees involving subject extraction. So the following will
not be ruled out.

\enumsentence{
the toy [$\epsilon$$_{i}$ [$\epsilon$$_{C}$ [ Dafna likes t$_{i}$ ]]] }


The feature mismatch induced by the above equations
is not remedied by adjunction of just any S-adjunct
because all other S-adjuncts
are transparent to the {\bf $\langle$rel-pron$\rangle$} feature
because of the following equation:

\enumsentence{
{\bf S$_{m}$.b:$\langle$rel-pron$\rangle =$ S$_{f}$.t:$\langle$rel-pron$\rangle$}}


{\bf $\langle$rel-clause$\rangle$}:\\ The XTAG analysis forces the
adjunction of the determiner below the relative clause. This is done
by using the {\bf $\langle$rel-clause$\rangle$} feature. The relevant
equations are:

\enumsentence{ On the root of the RC: {\bf NP$_{r}$.b:$\langle$rel-clause$\rangle = +$}}
\enumsentence{ On the foot node of the 
Determiner tree: {\bf NP$_{f}$.t:$\langle$rel-clause$\rangle = -$}}




\section{Complementizer Selection}
The following features are used to ensure the appropriate distribution
of complementizers:
\\
{\bf $\langle$comp$\rangle$}, possible values: {\bf that, if, whether,
for, rel, inf\_nil, ind\_nil, nil}\\
{\bf $\langle$assign-comp$\rangle$}, possible values: {\bf that, if,
whether, for, ecm, rel, ind\_nil, inf\_nil, none}\\
{\bf $\langle$mode$\rangle$}, possible values: {\bf ind, inf, sbjnct, ger, base, ppart, 
nom, prep}\\
{\bf $\langle$wh$\rangle$}, possible values: {\bf +, --}

The value of the {\bf $\langle$comp$\rangle$} feature tells us what complementizer we 
are dealing with. The trees which introduce complementizers come 
specified from the lexicon with their 
{\bf $\langle$comp$\rangle$} feature and {\bf $\langle$assign-comp$\rangle$} 
feature. The {\bf $\langle$comp$\rangle$} of the Comp tree regulates 
what kind of tree goes above the Comp tree, while the 
{\bf $\langle$assign-comp$\rangle$} feature regulates what kind of tree
goes below.
e.g.
the following equations are used for {\em that}:

\enumsentence{ {\bf S$_{c}$.b:$\langle$comp$\rangle =$ Comp.t:$\langle$comp$\rangle$} }
\enumsentence{ {\bf S$_{c}$.b:$\langle$wh$\rangle =$ Comp.t:$\langle$wh$\rangle$}}
\enumsentence{ {\bf S$_{c}$.b:$\langle$mode$\rangle =$ ind/sbjnct}}
\enumsentence{ {\bf S$_{r}$.t:$\langle$assign-comp$\rangle =$ Comp.t:$\langle$comp$\rangle$}}
\enumsentence{ {\bf S$_{r}$.b:$\langle$comp$\rangle =$ nil}}

By specifying {\bf S$_{r}$.b:$\langle$comp$\rangle =$ nil}, we ensure that
complementizers do not adjoin onto other complementizers. The root node
of a complementizer tree always has its {\bf $\langle$comp$\rangle$} feature
set to a value other than {\bf nil}.

Trees that take clausal complements specify with the {\bf $\langle$comp$\rangle$} feature
on their foot node what kind of complementizer(s) they can take. 
The {\bf $\langle$assign-comp$\rangle$} feature of an S node is determined 
by the highest VP below the S node and the syntactic configuration
the S node is in. 

\subsection{Verbs with object sentential complements}
Finite sentential complements:

\enumsentence{ {\bf S$_{1}$.t:$\langle$comp$\rangle =$ that/whether/if/nil}}
\enumsentence{{\bf S$_{1}$.t:$\langle$mode$\rangle =$ ind/sbjnct} or {\bf S$_{1}$.t:$\langle$mode$\rangle =$ ind}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$assign-comp$\rangle =$ ind\_nil/inf\_nil}}

The presence of an overt complementizer is optional.

Non-finite sentential complements, do not permit {\em for}:

\enumsentence{ {\bf S$_{1}$.t:$\langle$comp$\rangle =$ nil}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$mode$\rangle =$ inf}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$assign-comp$\rangle =$ ind\_nil/inf\_nil}
}

Non-finite sentential complements, permit {\em for}:

\enumsentence{ {\bf S$_{1}$.t:$\langle$comp$\rangle =$ for/nil}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$mode$\rangle =$ inf}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$assign-comp$\rangle =$ ind\_nil/inf\_nil}}

Cases like `*I want for to win' are independently ruled out due to a 
case feature clash between the {\bf acc} assigned by {\em for} and the
intrinsic case feature {\bf none} on the PRO.

Non-finite sentential complements, ECM:

\enumsentence{ {\bf S$_{1}$.t:$\langle$comp$\rangle =$ nil}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$mode$\rangle =$ inf}}
\enumsentence{ {\bf S$_{1}$.t:$\langle$assign-comp$\rangle =$ ecm}}


\subsection{Verbs with sentential subjects}
The following contrast involving complementizers surfaces with sentential
subjects:

\enumsentence{ *(That) John is crazy is likely.}

Indicative sentential subjects obligatorily have complementizers while
infinitival sentential subjects may or may not have a complementizer. 
Also {\em if} is possible as the complementizer of an object clause
but not as the complementizer of a sentential subject. 

\enumsentence{ {\bf S$_{0}$.t:$\langle$comp$\rangle =$ that/whether/for/nil}}
\enumsentence{ {\bf S$_{0}$.t:$\langle$mode$\rangle =$ inf/ind}}
\enumsentence{ {\bf S$_{0}$.t:$\langle$assign-comp$\rangle =$ inf\_nil}}

If the sentential subject is finite and a complementizer does
not adjoin in, the {\bf $\langle$assign-comp$\rangle$} feature of the 
S$_{0}$ node of the embedding clause and the root node of the
embedded clause will fail to unify. If a complementizer adjoins in,
there will be no feature-mismatch because the root of the
complementizer tree is not specified for the {\bf $\langle$assign-comp$\rangle$} feature.

The {\bf $\langle$comp$\rangle$} feature {\bf nil} is split into two
{\bf $\langle$assign-comp$\rangle$} features {\bf ind\_nil} and
{\bf inf\_nil} to capture the fact that there are certain configurations in
which it is acceptable for an infinitival clause to lack a complementizer
but not acceptable for an indicative clause to lack a complementizer. 

\subsection{{\em That}-trace and {\em for}-trace effects}

\enumsentence{ Who$_{i}$ do you think (*that) t$_{i}$ ate the apple?}

{\em That} trace violations are blocked by the presence of the following
equation:

\enumsentence{ {\bf S$_{r}$.b:$\langle$assign-comp$\rangle =$ inf\_nil/ind\_nil/ecm}}

on the bottom of the S$_{r}$ nodes of trees with extracted subjects (W0). 
The {\bf ind\_nil} feature specification permits the above example
while the {\bf inf\_nil/ecm} feature specification allows the
following examples to be derived:

\enumsentence{ Who$_{i}$ do you want [ t$_{i}$ to win the World Cup]?}
\enumsentence{ Who$_{i}$ do you consider [ t$_{i}$ intelligent]?}

The feature equation that ruled out the {\em that}-trace filter violations
will also serve to rule out the {\em for}-trace violations above.

\section{Determiner ordering}
{\bf $\langle$card$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$compl$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$const$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$decreas$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$definite$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$gen$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$quan$\rangle$}, possible values are {\bf +, --}

For detailed discussion see Chapter \ref{det-comparitives}.

\section{Punctuation}
{\bf $\langle$punct$\rangle$} is a complex feature. It has the following
as its subfeatures:\\
{\bf $\langle$punct bal$\rangle$}, possible values are {\bf dquote,
squote, paren, nil}\\
{\bf $\langle$punct contains dquote$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$punct contains squote$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$punct struct$\rangle$}, possible values are {\bf comma,
dash, colon, scolon, none, nil}\\
{\bf $\langle$punct term$\rangle$}, possible values are {\bf per, qmark, excl, 
none, nil}

For detailed discussion see Chapter~\ref{punct-chapt}.


\section{Conjunction}
{\bf $\langle$conj$\rangle$}, possible values are {\bf but, and, or,
comma, scolon, to, nil}\\
The {\bf $\langle$conj$\rangle$} feature is specified in the lexicon
for each conjunction and is passed up to the root node 
of the conjunction tree. If the conjunction is {\em and}, the 
root {\bf $\langle$agr num$\rangle$} is {\bf $\langle$plural$\rangle$}, no
matter what the number of the two conjuncts. With {\em or}, the
the root {\bf $\langle$agr num$\rangle$} is equated to the
{\bf $\langle$agr num$\rangle$} feature of the right conjunct. 


{\bf $\langle$disc-conj$\rangle$}, possible values are {\bf +, --}\\
This feature is only used in the $\beta$CONJs tree.
It blocks the adjunction of one $\beta$CONJs tree on another.
The following equations are used (note that S$_{r}$ is the foot node
and S$_{c}$ is the root node):
\enumsentence{ S$_{r}$.t:$\langle$disc-conj$\rangle$ = -}
\enumsentence{ S$_{c}$.b:$\langle$disc-conj$\rangle$ = +}


\section{Comparatives}
{\bf $\langle$compar$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$equiv$\rangle$}, possible values are {\bf +, --}\\
{\bf $\langle$super$\rangle$}, possible values are {\bf +, --}

For detailed discussion see Chapter~\ref{compars-chapter}.

\section{Control}
{\bf $\langle$control$\rangle$} has no value and is used only for indexing
purposes.  The root node of every clausal tree has its {\bf
$\langle$control$\rangle$} feature coindexed with the control feature of
its subject.  This allows adjunct control to take place. In addition,
clauses that take infinitival clausal complements have the control feature
of their subject/object coindexed with the control feature of their
complement clause S, depending upon whether they are subject control verbs
or object control verbs respectively.


\section{Other Features}
{\bf $\langle$neg$\rangle$}, possible values are {\bf +, --}\\
Used for controlling the interaction of negation and auxiliary verbs.

{\bf $\langle$pred$\rangle$}, possible values are {\bf +, --}\\
The {\bf $\langle$pred$\rangle$} feature is used in the following tree
families: Tnx0N1.trees and Tnx0nx1ARB.trees.
In the Tnx0N1.trees family, the following equations are used:\\
for $\alpha$W1nx0N1:

\enumsentence{ NP$_{1}$.t:$\langle$pred$\rangle$ = +}
\enumsentence{ NP$_{1}$.b:$\langle$pred$\rangle$ = +}
\enumsentence{ NP.t:$\langle$pred$\rangle$ = +}
\enumsentence{ N.t:$\langle$pred$\rangle$ = NP.b:$\langle$pred$\rangle$}

This is the only tree in this tree family to use the 
{\bf $\langle$pred$\rangle$} feature.

The other tree family where the {\bf $\langle$pred$\rangle$} feature is
used is Tnx0nx1ARB.trees.  Within this family, this feature (and the
following equations) are used only in the $\alpha$W1nx0nx1ARB tree.

\enumsentence{ AdvP$_{1}$.t:$\langle$pred$\rangle$ = +}
\enumsentence{ AdvP$_{1}$.b:$\langle$pred$\rangle$ = +}
\enumsentence{ NP.t:$\langle$pred$\rangle$ = +}
\enumsentence{ AdvP.b:$\langle$pred$\rangle$ = NP.t:$\langle$pred$\rangle$}


{\bf $\langle$pron$\rangle$}, possible values are {\bf +, --}\\
This feature indicates whether a particular NP is a pronoun or not. 
Certain constructions which do not permit pronouns use this 
feature to block pronouns.

{\bf $\langle$tense$\rangle$}, possible values are {\bf pres, past}\\
It does not seem to be the case that the {\bf $\langle$tense$\rangle$}
feature interacts with other features/syntactic processes. It 
comes from the lexicon with the verb and is transmitted up the
tree in such a way that the root S node ends up with the
tense feature of the highest verb in the tree. The equations
used for this purpose are:

\enumsentence{ {\bf S$_{r}$.b:$\langle$tense$\rangle$ = VP.t:$\langle$tense$\rangle$}}
\enumsentence{ {\bf VP.b:$\langle$tense$\rangle$ = V.t:$\langle$tense$\rangle$}}


{\bf $\langle$trans$\rangle$}, possible values are {\bf +, --}\\
Many but not all English verbs can anchor both transitive and intransitive trees.

\enumsentence{ The sun melted the ice cream.}
\enumsentence{ The ice cream melted.}
\enumsentence{ Elmo borrowed a book.}
\enumsentence{ * A book borrowed.}

Transitive trees have the {\bf $\langle$trans$\rangle$} feature of their
anchor set to {\ +} and intransitive trees have the 
{\bf $\langle$trans$\rangle$} feature of their
anchor set to {\ --}. Verbs such as {\em melt} which can occur 
in both transitive and intransitive trees come unspecified for the 
{\bf $\langle$trans$\rangle$} feature from the lexicon. Verbs which 
can only occur in transitive trees e.g. {\em borrow} have their
{\bf $\langle$trans$\rangle$} feature 
specified in the lexicon as {\bf +} thus blocking their anchoring of 
an intransitive tree.


