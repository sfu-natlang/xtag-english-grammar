head	1.11;
access
	egedi
	beth
	cdoran
	srini
	anoop
	elhuang
	heatherm
	rjprasad
	timf
	prolo
	jason2
	fxia
	tbleam;
symbols;
locks; strict;
comment	@% @;


1.11
date	2000.11.10.19.19.11;	author anoop;	state Exp;
branches;
next	1.10;

1.10
date	2000.11.09.20.25.26;	author anoop;	state Exp;
branches;
next	1.9;

1.9
date	98.09.16.19.04.55;	author anoop;	state Exp;
branches;
next	1.8;

1.8
date	98.06.15.19.56.49;	author cdoran;	state Exp;
branches;
next	1.7;

1.7
date	95.01.26.18.06.02;	author egedi;	state Exp;
branches;
next	1.6;

1.6
date	95.01.24.20.33.48;	author egedi;	state Exp;
branches;
next	1.5;

1.5
date	94.12.13.21.07.29;	author beth;	state Exp;
branches;
next	1.4;

1.4
date	94.08.22.17.25.33;	author egedi;	state Exp;
branches;
next	1.3;

1.3
date	94.02.23.13.03.02;	author egedi;	state Exp;
branches;
next	1.2;

1.2
date	94.02.16.16.31.58;	author egedi;	state Exp;
branches;
next	1.1;

1.1
date	93.12.13.15.51.32;	author egedi;	state Exp;
branches;
next	;


desc
@Introduction section
@


1.11
log
@corrected errors
@
text
@
\chapter{Introduction to Lexicalized Tree Adjoining Grammars}
\label{intro-FBLTAG}

Tree-adjoining grammar (TAG) is a formal tree rewriting system. TAG and
Lexicalized Tree-Adjoining Grammar (LTAG) have been extensively studied
both with respect to their formal properties and to their linguistic
relevance. TAG and LTAG are formally equivalent, however, from the
linguistic perspective LTAG is the system we will be concerned with in
the XTAG system. We will often use these terms TAG and LTAG
interchangeably.

The motivations for the study of LTAG are both linguistic and formal.
The elementary objects manipulated by LTAG are structured objects
(trees or directed acyclic graphs) and not strings. Using structured
objects as the elementary objects of the formal system, it is possible
to construct formalisms whose properties relate directly to the study
of strong generative capacity (i.e., structural descriptions), which is
more relevant to the linguistic descriptions than the weak generative
capacity (sets of strings).

Each grammar formalism specifies a domain of locality, i.e., a domain
over which various dependencies (syntactic and semantic) can be
specified. It turns out that the various properties of a formalism
(syntactic, semantic, computational, and even psycholinguistic) follow,
to a large extent, from the initial specification of the domain of
locality.

\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=3in]{ps/intro-files/cfg-locality.eps}
\caption{\label{cfg} Domain of locality of a context-free grammar}
\end{center}
\end{figure*}

\subsection{Domain of locality of CFGs} 

In a context-free grammar (CFG) the domain of locality is the one level
tree corresponding to a rule in a CFG (Fig.~\ref{cfg}). It is easily
seen that the arguments of a predicate (for example, the two arguments
of {\it likes}) are not in the same local domain. The two arguments are
distributed over the two rules (two domains of locality)-- $S
\rightarrow NP \ VP$ and $VP \rightarrow V \ NP$. They can be brought
together by introducing a rule $S \rightarrow NP \ V \ VP $. However,
then the structure provided by the VP node is lost. We should also note
here that not every rule (domain) in the CFG in (Fig.~\ref{cfg}) is
lexicalized. The three rules on the right are lexicalized, i.e., they
have a lexical anchor. The rules on the right are not lexicalized. The
second and the third rules on the left are almost lexicalized, in the
sense that they each have a preterminal category ($V$ in the second
rule and $ADV$ in the third rule), i.e., by replacing $V$ by {\it
likes} and $ADV$ by {\it passionately} these two rules will become
lexicalized. However, the first rule on the left ($S \rightarrow NP
\ VP$) cannot be lexicalized. Can a CFG be lexicalized, i.e., given a
CFG, $G$, can we construct another CFG, $G'$, such that every rule in
$G'$ is lexicalized and $T(G)$, the set of (sentential) trees (i.e.,
the tree language of $G$) is the same as the tree language $T(G')$ of
$G'$? It can be shown that this is not the case \cite{joshischabes96}.
Of course, if we require that only the string languages of $G$ and $G'$
be the same (i.e., they are weakly equivalent) then any CFG can be
lexicalized. This follows from the fact that any CFG can be put in the
Greibach normal form where each rule is of the form $ A \rightarrow w
\ B1 \ B2 \ ... \ Bn$ where $w$ is a lexical item and the $B's$ are
nonterminals. The lexicalization we are interested in requires the
tree languages (i.e., the set of structural descriptions) be the same,
i.e., we are interested in the `strong' lexicalization. To summarize, a
CFG cannot be strongly lexicalized by a CFG. This follows from the fact
that the domain of locality of CFG is a one level tree corresponding to
a rule in the grammar. Note that there are two issues we are concerned
with here-- lexicalization of each elementary domain and the
encapsulation of the arguments of the lexical anchor in the elementary
domain of locality. The second issue is independent of the first issue.
From the mathematical point of view the first issue, i.e., the
lexicalization of the elementary domains of locality is the crucial
one. We can obtain strong lexicalization without satisfying the
requirement specified in the second issue (encapsulation of the
arguments of the lexical anchor). Of course, from the linguistic point
view the second issue is very crucial. What this means is that among
all possible strong lexicalizations we should choose only those that
meet the requirements of the second issue. In implementing a grammar in
the XTAG system we will assume that we always make such a choice.


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=1.5in]{ps/intro-files/schematic-subst2.eps}
\caption{\label{substitution} Substitution}
\end{center}
\end{figure*}

\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=2.5in]{ps/intro-files/treesubst.eps}
\caption{\label{tsg} Tree substitution grammar}
\end{center}
\end{figure*}

\subsection{Lexicalization of CFGs}

Now we can ask the following question. Can we strongly lexicalize a
CFG by a grammar with a larger domain of locality?
Fig.~\ref{substitution} and Fig.~\ref{tsg} show a tree substitution
grammar where the elementary objects (building blocks) are the three
trees in Fig.~\ref{tsg} and the combining operation is the tree
substitution operation shown in Fig.~\ref{substitution}. Note that
each tree in the tree substitution grammar (TSG), $G'$ is lexicalized,
i.e., it has a lexical anchor. It is easily seen that $G'$ indeed
strongly lexicalizes $G$. However, TSG's fail to strongly lexicalize
CFG's in general. We show this by an example. Consider the CFG, $G$,
in Fig.~\ref{tsg2} and a proposed TSG, $G'$. It is easily seen that
although $G$ and $G'$ are weakly equivalent they are not strongly
equivalent. In $G'$, suppose we start with the tree $\alpha_1$ then by
repeated substitutions of trees in $G'$ (a node marked with a vertical
arrow denotes a substitution site) we can grow the right side of
$\alpha_1$ as much as we want but we cannot grow the left
side. Similarly for $\alpha_2$ we can grow the left side as much as we
want but not the right side. However, trees in $G$ can grow on both
sides. Hence, the TSG, $G'$, cannot strongly lexicalize the CFG, $G$
\cite{joshischabes96}.


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=1.8in]{ps/intro-files/treesubst-rec.eps}
\caption{\label{tsg2} A tree substitution grammar}
\end{center}
\end{figure*}


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=1.5in]{ps/intro-files/schematic-adjunction2.eps}
\caption{\label{adjunction} Adjoining}
\end{center}
\end{figure*}

\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=3in]{ps/intro-files/adj-arise.eps}
\caption{\label{tsg-adj} Adjoining arises out of lexicalization}
\end{center}
\end{figure*}

We now introduce a new operation called `adjoining' as shown in
Fig.~\ref{adjunction}. Adjoining involves splicing (inserting) one
tree into another. More specifically, a tree $\beta$ as shown in
Fig.~\ref{adjunction} is inserted (adjoined) into the tree $\alpha$ at
the node $X$ resulting in the tree $\gamma$. The tree $\beta$, called
an auxiliary tree, has a special form. The root node is labeled with a
nonterminal, say $X$ and on the frontier there is also a node labeled
$X$ called the foot node (marked with *). There could be other nodes
(terminal or nonterminal) nodes on the frontier of $\beta$, the
nonterminal nodes will be marked as substitution sites (with a
vertical arrow). Thus if there is another occurrence of $X$ (other
than the foot node marked with *) on the frontier of $\beta$ it will
be marked with the vertical arrow and that will be a substitution
site. Given this specification, adjoining $\beta$ to $\alpha$ at the
node $X$ in $\alpha$ is uniquely defined. Adjoining can also be seen
as a pair of substitutions as follows: The subtree at $X$ in $\alpha$
is detached, $\beta$ is substituted at $X$ and the detached subtree is
then substituted at the foot node of $\beta$. A tree substitution
grammar when augmented with the adjoining operation is called a
tree-adjoining grammar (lexicalized tree-adjoining grammar because
each elementary tree is lexically anchored). In short, LTAG consists
of a finite set of elementary trees, each lexicalized with at least
one lexical anchor. The elementary trees are either initial or
auxiliary trees. Auxiliary trees have been defined already. Initial
trees are those for which all nonterminal nodes on the frontier are
substitution nodes. It can be shown that any CFG can be strongly
lexicalized by an LTAG~\cite{joshischabes96}.

In Fig.~\ref{tsg-adj} we show a TSG, $G'$, augmented by the operation
of adjoining, which strongly lexicalizes the CFG, $G$. Note that the
LTAG looks the same as the TSG considered in Fig.~\ref{tsg2}. However,
now trees $\alpha_1$ and $\alpha_2$ are auxiliary trees (marked with
*) that can participate in adjoining. Since adjoining can insert a
tree in the interior of another tree it is possible to grow both sides
of the tree $\alpha_1$ and tree $\alpha_2$, which was not possible
earlier with substitution alone. In summary, we have shown that by
increasing the domain of locality we have achieved the following: (1)
lexicalized each elementary domain, (2) introduced an operation of
adjoining, which would not be possible without the increased domain of
locality (note that with one level trees as elementary domains
adjoining becomes the same as substitution since there are no interior
nodes to be operated upon), and (3) achieved strong lexicalization of
CFGs.


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=2in]{ps/intro-files/likes-ex.eps}
\caption{\label{trees-likes} LTAG: Elementary trees for {\it likes}}
\end{center}
\end{figure*}

\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=2in]{ps/intro-files/ltag-sampletrees.eps}
\caption{\label{more-trees} LTAG: Sample elementary trees}
\end{center}
\end{figure*}

\subsection{Lexicalized tree-adjoining grammars}

Rather than giving formal definitions for LTAG and derivations in LTAG
we will give a simple example to illustrate some key aspects of
LTAG. We show some elementary trees of a toy LTAG grammar of
English. Fig.~\ref{trees-likes} shows two elementary trees for a verb
such as {\it likes}. The tree $\alpha_1$ is anchored on {\it likes}
and encapsulates the two arguments of the verb. The tree $\alpha_2$
corresponds to the object extraction construction. Since we need to
encapsulate all the arguments of the verb in each elementary tree for
{\it likes}, for the object extraction construction, for example, we
need to make the elementary tree associated with {\it likes} large
enough so that the extracted argument is in the same elementary
domain. Thus, in principle, for each `minimal' construction in which
{\it likes} can appear (for example, subject extraction,
topicalization, subject relative, object relative, passive, etc.)
there will be an elementary tree associated with that construction. By
`minimal' we mean when all recursion has been factored away. This
factoring of recursion away from the domain over which the
dependencies have to be specified is a crucial aspect of LTAGs as they
are used in linguistic descriptions. This factoring allows all
dependencies to be localized in the elementary domains. In this sense,
there will, therefore, be no long distance dependencies as such. They
will all be local and will become long distance on account of the
composition operations, especially adjoining.


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=2.5in]{ps/intro-files/ltag-derivation.eps}
\caption{\label{ltag-derivation} LTAG derivation for {\it who does Bill think Harry likes}}
\end{center}
\end{figure*}

Fig.~\ref{more-trees} shows some additional trees. Trees $\alpha_3$,
$\alpha_4$, and $\alpha_5$ are initial trees and trees $\beta_1$ and
$\beta_2$ are auxiliary trees with foot nodes marked with *. A
derivation using the trees in Fig.~\ref{more-trees} is shown in
Fig.~\ref{ltag-derivation}. The trees for {\it who} and {\it Harry}
are substituted in the tree for {\it likes} at the respective $NP$
nodes, the tree for {\it Bill} is substituted in the tree for {\it
think} at the $NP$ node, the tree for {\it does} is adjoined to the
root node of the tree for {\it think} tree (adjoining at the root node
is a special case of adjoining), and finally the derived auxiliary
tree (after adjoining $\beta_2$ to $\beta_1$) is adjoined to the
indicated interior $S$ node of the tree $\alpha_2$. This derivation
results in the derived tree for {\it who does Bill think Harry likes}
as shown in Fig.~\ref{derived-tree}. Note that the dependency between
{\it who} and the complement $NP$ in $\alpha_2$ (local to that tree)
has been stretched in the derived tree in
Fig.~\ref{derived-tree}. This tree is the conventional tree associated
with the sentence.


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=2.5in]{ps/intro-files/ltag-derived-tree.eps}
\caption{\label{derived-tree} LTAG derived tree for {\it who does Bill think Harry likes}}
\end{center}
\end{figure*}


However, in LTAG there is also a derivation tree, the tree that
records the history of composition of the elementary trees associated
with the lexical items in the sentence. This derivation tree is shown
in Fig.~\ref{ltag-derivation-tree}. The nodes of the tree are labeled
by the tree labels such as $\alpha_2$ together with the lexical
anchor\footnote{The derivation trees of LTAG have a close relationship
to the dependency trees, although there are some crucial differences;
however, the semantic dependencies are the same.}.  The derivation
tree is the crucial derivation structure for LTAG. We can obviously
build the derived tree from the derivation tree. For semantic
computation the derivation tree (and not the derived tree) is the
crucial object. Compositional semantics is defined on the derivation
tree. The idea is that for each elementary tree there is a semantic
representation associated with it and these representations are
composed using the derivation tree. Since the semantic representation
for each elementary tree is directly associated with the tree there is
no need to reproduce necessarily the internal hierarchy in the
elementary tree in the semantic
representation~\cite{joshi99:_compos_ltag}. This allows the so-called
`flat' semantic representation as well as helps in dealing with some
non-compositional aspects as in the case of rigid and flexible idioms.


\begin{figure*}[ht] 
\begin{center}
\includegraphics[height=1.5in]{ps/intro-files/ltag-derivation-tree.eps}
\caption{\label{ltag-derivation-tree} LTAG derivation tree}
\end{center}
\end{figure*}

\section{Some important properties of LTAG}

The two key properties of LTAG are (1) extended domain of locality
(EDL) (for example, as compared to CFG), which allows (2) factoring
recursion from the domain of dependencies (FRD), thus making all
dependencies local. All other properties of LTAG (mathematical,
linguistic, and even psycholinguistic) follow from EDL and FRD. TAGs
(LTAGs) belong to the so-called class of mildly context-sensitive
grammars~\cite{joshi85}. CFL's are properly contained in the class of
languages of LTAG, which in turn are properly contained in the class
of context-sensitive languages. There is a machine characterization of
TAG (LTAG), called embedded pushdown automaton (EPDA)~\cite{vijay87},
i.e., for every TAG language there is an EPDA which corresponds to
this (and only this) language and the language accepted by any EPDA is
a TAG language. EPDAs have been used to model some psycholinguistic
phenomena, for example, processing crossed dependencies and nested
dependencies have been in discussed in~\cite{joshi90}. With respect to
formal properties, the class of TAG languages enjoys all the important
properties of CFLs, including polynomial parsing (with complexity
$O(n^{6}$)).

\section{Unification-based features}

In the XTAG system, each node in each LTAG tree is decorated with two
feature structures (top and bottom feature structures), in contrast to
the CFG based feature structure grammars, because adjoining can augment
a tree internally, while in a CFG based grammar a tree can be augmented
only at the frontier. It is possible to define adjoining and
substitution (as it is done in the XTAG system) in terms of appropriate
unifications of the top and bottom feature structures. Because of FRD
(factoring recursion from the domain of dependencies), there is no
recursion in the feature structures. Therefore, in principle, feature
structures can be eliminated. However, they are crucial for linguistic
descriptions. Constraints on substitution and adjoining are modeled via
these feature structures~\cite{vijay87}. This method of manipulating
feature structures is a direct consequence of the extended domain of
locality of LTAG.

In a unification framework, a feature structure is associated with each
node in an elementary tree.  This feature structure contains
information about how the node interacts with other nodes in the tree.
It consists of a top part, which generally contains information
relating to the supernode, and a bottom part, which generally contains
information relating to the subnode.  Substitution nodes, however, have
only the top features, since the tree substituting in logically carries
the bottom features.

\begin{figure}[htb]
\centering
\begin{tabular}{c}
\includegraphics[height=1.5in]{ps/intro-files/schematic-feat-subst.eps}
\end{tabular}
\caption{Substitution in FB-LTAG}
\label{subst-fig}
\end{figure}

The notions of substitution and adjunction must be augmented to fit
within this new framework.  The feature structure of a new node created
by substitution inherits the union of the features of the original
nodes.  The top feature of the new node is the union of the top
features of the two original nodes, while the bottom feature of the new
node is simply the bottom feature of the top node of the substituting
tree (since the substitution node has no bottom feature).  Figure
\ref{subst-fig}\footnote{abbreviations in the figure:  t$=$top feature
structure, tr$=$top feature structure of the root, br$=$bottom feature
structure of the root, U$=$unification} shows this more clearly.

\begin{figure}[htb]
\centering
\begin{tabular}{c}
\hspace{0.65in}
\includegraphics[height=1.5in]{ps/intro-files/schematic-feat-adjunction.eps}
\end{tabular}
\caption{Adjunction in FB-LTAG}
\label{adjunct-fig}
\end{figure}

Adjunction is only slightly more complicated.  The node being adjoined into
splits, and its top feature unifies with the top feature of the root
adjoining node, while its bottom feature unifies with the bottom feature of the
foot adjoining node.  Again, this is easier shown graphically, as in Figure
\ref{adjunct-fig}\footnote{abbreviations in the figure: t$=$top
feature structure, b$=$bottom feature structure, tr$=$top feature
structure of the root, br$=$bottom feature structure of the root,
tf$=$top feature structure of the foot, bf$=$bottom feature structure
of the foot, U$=$unification}.

\begin{figure}[htbp]
\centering
\begin{tabular}{ccc}
\includegraphics[height=4.5in]{ps/intro-files/think-feat.eps}  &
\hspace{0.6in}
\includegraphics[height=4.5in]{ps/intro-files/want-feat.eps} \\
{\it think} tree&{\it want} tree\\
\end{tabular}\\
\caption {Lexicalized Elementary Trees with Features}
\label {lex-with-features}
\label{2;Tnx0Vs1}
\end{figure}


The embedding of the TAG formalism in a unification framework allows
us to dynamically specify local constraints that would have otherwise
had to have been made statically within the trees.  Constraints that
verbs make on their complements, for instance, can be implemented
through the feature structures.  The notions of Obligatory and
Selective Adjunction, crucial to the formation of lexicalized
grammars, can also be handled through the use of
features.\footnote{The remaining constraint, Null Adjunction (NA),
must still be specified directly on a node.} Perhaps more important to
developing a grammar, though, is that the trees can serve as a
schemata to be instantiated with lexical-specific features when an
anchor is associated with the tree.  To illustrate this, Figure
\ref{lex-with-features} shows the same tree lexicalized with two
different verbs, each of which instantiates the features of the tree
according to its lexical selectional restrictions.

In Figure \ref{lex-with-features}, the lexical item {\it thinks} takes an
indicative sentential complement, as in the sentence {\it John thinks that Mary
loves Sally}.  {\it Want} takes a sentential complement as well, but an
infinitive one, as in {\it John wants to love Mary}.  This distinction is
easily captured in the features and passed to other nodes to constrain which
trees this tree can adjoin into, both cutting down the number of separate trees
needed and enforcing conceptual Selective Adjunctions (SA).

\section{Some related systems}

{\bf Categorial Grammars:} Categories assigned to lexical items in a
categorial grammar framework do encapsulate the arguments of the
lexical anchor. It is of interest to see how the basic ideas in LTAG
could be incorporated in a categorial framework. The idea is not to
translate LTAG into a categorial grammar but rather construct a
categorial system with properties similar to LTAG. This is achieved by
associating partial proof trees with lexical items. These partial
proof trees are obtained by starting with the type assignment for a
lexical item as specified by a categorial grammar and then `unfolding'
it by using certain categorial inference rules such as function
application. This unfolding is done until the slots for the arguments
of the lexical anchor are exposed. We thus have a finite collection of
partial proof trees (lexicalized, of course) which serve as the
building blocks of our system (analogous to the finite set of
elementary trees in LTAG). These proof trees are then combined by
universal categorial inference rules in terms of cuts. Informally
speaking, the proof trees are hooked up by linking the conclusion
nodes of one tree to the assumption nodes of another tree. For a
further discussion of such systems and their relationship to LTAG can
be found in \cite{JoshiKulick97,joshi99:_proof_trees}.

{\bf From sentence structure to discourse structure:} Using the
insights from LTAG a structural and presuppositional a ccount of local
discourse structure has been presented
in~\cite{webber99:_discourse_tag}. The idea is to start the analysis
of discourse in the same way as one starts the analysis of a clause,
looking at how its syntax and semantics project from the lexicon. This
is complementary to the issue of discourse pragmatics --how these
small syntactic units of discourse are used in achieving communicative
intentions --and to the other discourse processes that provide
additional organizational overlays on these units. A key feature of
this approach is that semantic discourse relations are associated with
syntactic structures and anaphoric links, and that the properties of
the two are (not surprisingly) different. Together they allow more
complex semantics to be conveyed through simpler structures.

{\bf Phrase structure composition and syntactic dependencies:}
\cite{frank00:_tag_book} presents a comprehensive perspective on phrase
structure composition and syntactic dependencies in a TAG-based
grammatical architecture and compares it to the minimalist framework,
showing that a number of stipulative and problematic aspects of that
theory can be eliminated.



\section{Summary}

The domain of locality of a grammar formalism, i.e., the domain over
which various dependencies can be specified determines to a large
extent the syntactic, semantic, computational, and even
psycholinguistic properties of the formalism. From this perspective the
extended domain of Lexicalized Tree-Adjoining Grammars (LTAG) --
extended as compared to the domain of locality of CFGs, for example --
was explored. This extended domain is achieved by specifying the
elementary objects of the grammar as structured objects instead of
strings, together with two universal combining operations (substitution
and adjoining). This perspective allows us to study directly many
aspects of strong generative capacity which are more useful for
linguistic description.

@


1.10
log
@changed to new introduction -- first draft
@
text
@d6 6
a11 5
Lexicalized Tree-Adjoining Grammar (LTAG) have been extensively studied both with
respect to their formal properties and to their linguistic relevance. TAG and
LTAG are formally equivalent, however, from the linguistic perspective LTAG is
the system we will be concerned with in this paper. We will often use these
terms TAG and LTAG interchangeably.
d13 8
a20 7
The motivations for the study of LTAG are both linguistic and formal. The
elementary objects manipulated by LTAG are structured objects (trees or
directed acyclic graphs) and not strings. Using structured objects as the
elementary objects of the formal system, it is possible to construct formalisms
whose properties relate directly to the study of strong generative capacity
(i.e., structural descriptions), which is more relevant to the linguistic
descriptions than the weak generative capacity (sets of strings). 
d22 6
a27 5
Each grammar formalism specifies a domain of locality, i.e., a domain over
which various dependencies (syntactic and semantic) can be specified. It turns
out that the various properties of a formalism (syntactic, semantic,
computational, and even psycholinguistic) follow, to a large extent, from the
initial specification of the domain of locality. 
d38 44
a81 45
In a context-free grammar (CFG) the domain of locality is the one
level tree corresponding to a rule in a CFG (Fig.~\ref{cfg}). It is
easily seen that the arguments of a predicate (for example, the two
arguments of {\it likes}) are not in the same local domain. The two
arguments are distributed over the two rules (two domains of
locality)-- $S \rightarrow NP \ VP$ and $VP \rightarrow V \ NP$. They
can be brought together by introducing a rule $S \rightarrow NP \ V \
VP $. However, then the structure provided by the VP node is lost. We
should also note here that not every rule (domain) in the CFG in
(Fig.~\ref{cfg}) is lexicalized. The three rules on the right are
lexicalized, i.e., they have a lexical anchor. The rules on the right
are not lexicalized. The second and the third rules on the left are
almost lexicalized, in the sense that they each have a preterminal
category ($V$ in the second rule and $ADV$ in the third rule), i.e.,
by replacing $V$ by {\it likes} and $ADV$ by {\it passionately} these
two rules will become lexicalized. However, the first rule on the left
($S \rightarrow NP \ VP$) cannot be lexicalized. Can a CFG be
lexicalized, i.e., given a CFG, $G$, can we construct another CFG,
$G'$, such that every rule in $G'$ is lexicalized and $T(G)$, the set
of (sentential) trees (i.e., the tree language of $G$) is the same as
the tree language $T(G')$ of $G'$? It can be shown that this is not
the case \cite{joshischabes96}.  Of course, if we require that only
the string languages of $G$ and $G'$ be the same (i.e., they are
weakly equivalent) then any CFG can be lexicalized. This follows from
the fact that any CFG can be put in the Greibach normal form where
each rule is of the form $ A \rightarrow w \ B1 \ B2 \ ... \ Bn$ where
$w$ is a lexical item and the $B's$ are nonterminals. The
lexicalization we are interested in req uires the tree languages
(i.e., the set of structural descriptions) be the same, i.e., we are
interested in the `strong' lexicalization. To summarize, a CFG cannot
be strongly lexicalized by a CFG. This follows from the fact that the
domain of locality of CFG is a one level tree corresponding to a rule
in the grammar. Note that there are two issues we are concerned with
here-- lexicalization of each elementary domain and the encapsulation
of the arguments of the lexical anchor in the elementary domain of
locality. The second issue is independent of the first issue. From the
mathematical point of view the first issue, i.e., the lexicalization
of the elementary domains of locality is the crucial one. We can
obtain strong lexicalization without satisfying the requirement
specified in the second issue (encapsulation of the arguments of the
lexical anchor). Of course, from the linguistic point view the second
issue is very crucial. What this means is that among all possible
strong lexicalizations we should choose only those that meet the
requirements of the second issue. For our discussions in this paper we
will assume that we always make such a choice.
d145 1
a145 1
Fig.~\ref{adjunction}. Adjoining involves splicing (in serting) one
d295 21
d318 14
a331 7
In a unification framework, a feature structure is associated with each node in
an elementary tree.  This feature structure contains information about how the
node interacts with other nodes in the tree.  It consists of a top part, which
generally contains information relating to the supernode, and a bottom part,
which generally contains information relating to the subnode.  Substitution
nodes, however, have only the top features, since the tree substituting in
logically carries the bottom features.
d333 9
d352 9
a360 10
within this new framework.  The feature structure of a new node
created by substitution inherits the union of the features of the
original nodes.  The top feature of the new node is the union of the
top features of the two original nodes, while the bottom feature of
the new node is simply the bottom feature of the top node of the
substituting tree (since the substitution node has no bottom feature).
Figure \ref{subst-fig}\footnote{abbreviations in the figure:
t$=$top feature structure, tr$=$top feature structure of the root, br$=$bottom
feature structure of the root, U$=$unification} shows this more
clearly.
a419 40
\section{Some important properties of LTAG}

The two key properties of LTAG are (1) extended domain of locality
(EDL) (for example, as compared to CFG), which allows (2) factoring
recursion from the domain of dependencies (FRD), thus making all
dependencies local. All other properties of LTAG (mathematical,
linguistic, and even psycholinguistic) follow from EDL and FRD. TAGs
(LTAGs) belong to the so-called class of mildly context-sensitive
grammars~\cite{joshi85}. CFL's are properly contained in the class of
languages of LTAG, which in turn are properly contained in the class
of context-sensitive languages. There is a machine characterization of
TAG (LTAG), called embedded pushdown automaton (EPDA)~\cite{vijay87},
i.e., for every TAG language there is an EPDA which corresponds to
this (and only this) language and the language accepted by any EPDA is
a TAG language. EPDAs have been used to model some psycholinguistic
phenomena, for example, processing crossed dependencies and nested
dependencies have been in discussed in~\cite{joshi90}. With respect to
formal properties, the class of TAG languages enjoys all the important
properties of CFLs, including polynomial parsing (with complexity
$O(n^{6}$)).

Large scale wide coverage grammars have been built using LTAG, the
XTAG system (LTAG grammar and lexicon for English and a parser) being
the largest so far (for further details see (The XTAG Research Group
(2000)). In the XTAG system, each node in each LTAG tree is decorated
with two feature structures (top and bottom feature structures), in
contrast to the CFG based feature structure grammars, because
adjoining can augment a tree internally, while in a CFG based grammar
a tree can be augmented only at the frontier. It is possible to define
adjoining and substitution (as it is done in the XTAG system) in terms
of appropriate unifications of the top and bottom feature
structures. Because of FRD (factoring recursion from the domain of
dependencies), there is no recursion in the feature
structures. Therefore, in principle, feature structures can be
eliminated. However, they are crucial for linguistic
descriptions. Constraints on substitution and adjoining are modeled
via these feature structures~\cite{vijay87}. This method of
manipulating feature structures is a direct consequence of the
extended domain of locality of LTAG.

d459 2
a460 2
\cite{frank00:_tag_book} presents a comprehensive perspective on ph
rase structure composition and syntactic dependencies in a TAG-based
d469 12
a480 10
The domain of locality of a grammar formalism, i.e., the domain over which
various dependencies can be specified determines to a large extent the
syntactic, semantic, computational, and even psycholinguistic properties of the
formalism. From this perspective the extended domain of Lexicalized
Tree-Adjoining Grammars (LTAG) -- extended as compared to the domain of locality
of CFGs, for example -- was explored. This extended domain is achieved by
specifying the elementary objects of the grammar as structured objects instead
of strings, together with two universal combining operations (substitution and
adjoining). This perspective allows us to study directly many aspects of strong
generative capacity which are more useful for linguistic description.  
@


1.9
log
@minor typo
@
text
@d1 2
a2 1
\chapter{Feature-Based, Lexicalized Tree Adjoining Grammars}
d5 6
a10 11
The English grammar described in this report is based on the TAG formalism
(\cite{joshi75}), which has been extended to include lexicalization
(\cite{schabes88}), and unification-based feature structures
(\cite{vijay91}). Tree Adjoining Languages (TALs) fall into the class of mildly
context-sensitive languages, and as such are more powerful than context free
languages.  The TAG formalism in general, and lexicalized TAGs in particular,
are well-suited for linguistic applications.  As first shown by \cite{joshi85}
and \cite{kj87}, the properties of TAGs permit us to encapsulate diverse
syntactic phenomena in a very natural way.  For example, TAG's extended domain
of locality and its factoring of recursion from local dependencies lead, among
other things, to a localization of so-called unbounded dependencies.
d12 7
a18 1
\section{TAG formalism}
d20 5
a24 9
The primitive elements of the standard TAG formalism are known as elementary
trees.  \xtagdef{Elementary trees} are of two types: initial trees and
auxiliary trees (see Figure \ref{elem-fig}).  In describing natural language,
\xtagdef{initial trees} are minimal linguistic structures that contain no
recursion, i.e. trees containing the phrasal structure of simple sentences,
NP's, PP's, and so forth.  Initial trees are characterized by the following: 1)
all internal nodes are labeled by non-terminals, 2) all leaf nodes are labeled
by terminals, or by non-terminal nodes marked for substitution. An initial tree
is called an X-type initial tree if its root is labeled with type X.
d26 6
a31 6
\begin{figure}[htb]
\centering
\psfig{figure=ps/intro-files/schematic-elem-trees.ps,height=1.9in}
\caption{Elementary trees in TAG}
\label{elem-fig}
\end{figure}
d33 1
a33 10
Recursive structures are represented by \xtagdef{auxiliary trees}, which
represent constituents that are adjuncts to basic structures (e.g. adverbials).
Auxiliary trees are characterized as follows: 1) all internal nodes are labeled
by non-terminals, 2) all leaf nodes are labeled by terminals, or by
non-terminal nodes marked for substitution, except for exactly one non-terminal
node, called the foot node, which can only be used to adjoin the tree to
another node\footnote{A null adjunction constraint (NA) is systematically put
on the foot node of an auxiliary tree. This disallows adjunction of a tree onto
the foot node itself.}, 3) the foot node has the same label as the root node of
the tree.
d35 45
a79 8
There are two operations defined in the TAG formalism,
substitution\footnote{Technically, substitution is a specialized version of
adjunction, but it is useful to make a distinction between the two.} and
adjunction.  In the \xtagdef{substitution} operation, the root node on an
initial tree is merged into a non-terminal leaf node marked for substitution in
another initial tree, producing a new tree.  The root node and the substitution
node must have the same name.  Figure \ref{proto-subst} shows two initial trees
and the tree resulting from the substitution of one tree into the other.
a80 6
\begin{figure}[htb]
\centering
\psfig{figure=ps/intro-files/schematic-subst2.ps,height=1.9in}
\caption{Substitution in TAG}
\label{proto-subst}
\end{figure}
d82 6
a87 5
In an \xtagdef{adjunction} operation, an auxiliary tree is grafted onto a
non-terminal node anywhere in an initial tree.  The root and foot nodes of the
auxiliary tree must match the node at which the auxiliary tree adjoins.  Figure
\ref{proto-adjunction} shows an auxiliary tree and an initial tree, and the
tree resulting from an adjunction operation.
d89 6
a94 6
\begin{figure}[htb]
\centering
\psfig{figure=ps/intro-files/schematic-adjunction2.ps,height=1.9in}
\caption{Adjunction in TAG}
\label{proto-adjunction}
\end{figure}
d96 1
a96 7
A TAG $G$ is a collection of finite initial trees, $I$, and auxiliary trees,
$A$.  The \xtagdef{tree set} of a TAG $G$, ${\cal T}(G)$ is defined to be the
set of all derived trees starting from S-type initial trees in $I$ whose
frontier consists of terminal nodes (all substitution nodes having been
filled). The \xtagdef{string language} generated by a TAG, ${\cal L}(G)$, is
defined to be the set of all terminal strings on the frontier of the trees in
${\cal T}(G)$.
d98 20
a117 1
\section{Lexicalization}
a118 6
`Lexicalized' grammars systematically associate each elementary structure with
a lexical anchor. This means that in each structure there is a lexical item
that is realized.  It does not mean simply adding feature structures (such as
head) and unification equations to the rules of the formalism.  These resultant
elementary structures specify extended domains of locality (as compared to
CFGs) over which constraints can be stated.
d120 6
a125 6
Following \cite{schabes88} we say that a grammar is \xtagdef{lexicalized} if it
consists of 1) a finite set of structures each associated with a lexical item,
and 2) an operation or operations for composing the structures.  Each lexical
item will be called the \xtagdef{anchor} of the corresponding structure, which
defines the domain of locality over which constraints are specified.  Note
then, that constraints are local with respect to their anchor.
a126 8
Not every grammar is in a lexicalized form.\footnote{Notice the similarity of
the definition of a lexicalized grammar with the off line parsability
constraint (\cite{kaplan83}). As consequences of our definition, each structure
has at least one lexical item (its anchor) attached to it and all sentences are
finitely ambiguous.} In the process of lexicalizing a grammar, the lexicalized
grammar is required to be strongly equivalent to the original grammar, i.e. it
must produce not only the same language, but the same structures or tree set as
well.
d128 5
a132 14
\begin{figure*}[htb]
\centering
\begin{tabular}{ccccccc}
{{\psfig{figure=ps/intro-files/john.ps,height=1.0in}}\label{fig1a}}  &
\hspace{0.1in} &
{{\psfig{figure=ps/intro-files/walked.ps,height=1.4in}}\label{fig1b}}  & 
\hspace{0.1in} &
{{\psfig{figure=ps/intro-files/to.ps,height=1.7in}} \label{fig1c} }  & 
\hspace{0.1in} &
{{\psfig{figure=ps/intro-files/philly.ps,height=1.0in}} \label{fig1d}} \\
(a)&&(b)&&(c)&&(d)\\
\end{tabular}\\
\caption {Lexicalized Elementary trees}
\label {lex-elem-trees}
d135 6
a140 4
In Figure \ref{lex-elem-trees}, which shows sample initial and auxiliary trees,
substitution sites are marked by a $\downarrow$, and foot nodes are marked by
an $\ast$.  This notation is standard and is followed in the rest of this
report.
d142 27
d170 123
d306 1
a306 1
\psfig{figure=ps/intro-files/schematic-feat-subst.ps,height=2.0in}
d328 1
a328 1
\psfig{figure=ps/intro-files/schematic-feat-adjunction.ps,height=2.0in}
d347 1
a347 1
{\psfig{figure=ps/intro-files/think-feat.ps,height=6.5in}}  &
d349 1
a349 1
{\psfig{figure=ps/intro-files/want-feat.ps,height=6.5in}} \\
d382 99
@


1.8
log
@Added cross-reference for table (table.tex).
@
text
@d35 1
a35 1
Recursive structures are represented by {\xtagdef{auxiliary trees}, which
@


1.7
log
@Changes from Tilman's proof-read.
@
text
@d191 1
@


1.6
log
@Results from final push.  This is the 'almost final' version.
@
text
@d1 1
a1 1
\chapter{Introduction to Feature-Based, Lexicalized Tree Adjoining Grammars}
d23 1
a23 1
NPs, PPs, and so forth.  Initial trees are characterized by the following: 1)
d75 7
a81 5
The tree set of a TAG $G$, ${\cal T}(G)$ is defined to be the set
of all derived trees starting from S-type initial trees in $I$ whose frontier
consists of terminal nodes (all substitution nodes having been filled). The
string language generated by a TAG, ${\cal L}(G)$, is defined to be the
set of all terminal strings on the frontier of the trees in ${\cal T}(G)$.
d100 1
a100 1
the definition of a lexicalized grammar with the off line parsibility
d120 1
a120 1
\caption {Lexicalized Elementary Trees}
d125 2
a126 2
substitution sites are marked by a ($\downarrow$), and foot nodes are marked by
an ($\ast$).  This notation is standard and is followed in the rest of this
d137 2
a138 2
nodes, however, have only the top features, since the tree substituting in must
logically carry the bottom features.
d175 1
a175 1
\ref{adjunct-fig}\footnote{abbreviations in the tree figure: t$=$top
d208 1
a208 1
according to its lexical semantics.
@


1.5
log
@typos fixed.
@
text
@d1 3
a3 1
\section{Introduction}
d5 10
a14 10
developed in Joshi, Levy, and Takahashi \cite{joshi75}, which has been extended
to include lexicalization \cite{schabes88}, and unification-based feature
structures \cite{vijay91}. Tree Adjoining Languages (TALs) fall into the class
of mildly context-sensitive languages, and as such are more powerful than
context free languages.  The TAG formalism in general, and lexicalized TAGs in
particular, are well-suited for linguistic applications.  As first shown by
\cite{joshi85} and \cite{kj87}, the properties of TAGs permit us to encapsulate
diverse syntactic phenomena in a very natural way.  For example, TAG's extended
domain of locality and its factoring of recursion from local dependencies lead,
among other things, to a localization of so-called unbounded dependencies.
d16 1
a16 1
\subsection{TAG formalism}
d18 4
a21 4
The primitive elements of the standard TAG formalism are known as {\sc
elementary trees}.  Elementary trees are of two types: {\sc initial trees} and
{\sc auxiliary trees} (see Figure \ref{elem-fig}).  In describing natural
language, {\sc initial trees} are minimal linguistic structures that contain no
d26 1
a26 1
is called an X-type initial tree if its root is labeled with type X.  
d28 1
a28 1
\begin{figure}[ht]
d30 1
a30 2
\rule[.1in]{\textwidth}{0.01in} 
\psfig{figure=ps/intro-files/schematic-elem-trees.ps,height=2.0in}
a31 1
\rule[.1in]{\textwidth}{0.01in} 
d35 4
a38 4
Recursive structures are represented by {\sc auxiliary trees}, which represent
constituents that are adjuncts to basic structures (e.g. adverbials).  {\sc
Auxiliary trees} are characterized as follows: 1) all internal nodes are
labeled by non-terminals, 2) all leaf nodes are labeled by terminals, or by
d42 2
a43 2
on the footnode of an auxiliary tree. This disallows adjunction of a tree onto
a footnode itself.}, 3) the foot node has the same label as the root node of
d49 5
a53 5
adjunction.  In the substitution operation, the root node on an initial tree is
merged into a non-terminal leaf node marked for substitution in another initial
tree, producing a new tree.  The root node and the substitution node must have
the same name.  Figure \ref{proto-subst} shows two initial trees and the tree
resulting from the substitution of one tree into the other.
d55 1
a55 1
\begin{figure}[ht]
d57 1
a57 2
\rule[.1in]{\textwidth}{0.01in} 
\psfig{figure=ps/intro-files/schematic-subst2.ps,height=2.0in}
a58 1
\rule[.1in]{\textwidth}{0.01in} 
d62 3
a64 3
In an adjunction operation, an auxiliary tree is grafted onto a non-terminal
node anywhere in an initial tree.  The root and foot nodes of the auxiliary
tree must match the node at which the auxiliary tree adjoins.  Figure
d68 1
a68 1
\begin{figure}[ht]
d70 1
a70 2
\rule[.1in]{\textwidth}{0.01in} 
\psfig{figure=ps/intro-files/schematic-adjunction2.ps,height=2.0in}
a71 1
\rule[.1in]{\textwidth}{0.01in} 
d81 1
a81 1
\subsection{Lexicalization}
d90 1
a90 1
Following \cite{schabes88} we say that a grammar is `lexicalized' if it
d93 1
a93 1
item will be called the {\it anchor} of the corresponding structure, which
d97 3
a99 3
Not every grammar is in a `lexicalized' form.\footnote{Notice the similarity of
the definition of `lexicalized' grammar with the off line parsibility
constraint \cite{kaplan83}. As consequences of our definition, each structure
d101 4
a104 4
finitely ambiguous.} In the process of lexicalizing a grammar, the
`lexicalized' grammar is required to be strongly equivalent to the original
grammar, i.e., it must produce not only the same language, but the same
structures or tree set as well.
d106 1
a106 1
\begin{figure*}[ht]
d108 1
a108 2
\rule[.1in]{\textwidth}{0.01in} 
\begin{tabular}{cccc}
d110 1
d112 1
d114 1
d116 1
a116 1
(a)&(b)&(c)&(d)\\
a118 1
\rule[.1in]{\textwidth}{0.01in} 
d128 1
a128 1
\subsection{Unification-based features}
d135 1
a135 1
nodes, however, have only the top features, since the tree substiuting in must
d138 1
a138 9
The notions of substitution and adjunction must be augmented to fit within this
new framework.  The feature structure of a new node created by substitution
inherits the union of the features of the original nodes.  The top feature of
the new node is the union of the top features of the two original nodes, while
the bottom feature of the new node is simply the bottom feature of the top node
of the subsituting tree (since the substitution node has no bottom feature).
Feature \ref{subst-fig} shows this more clearly.

\begin{figure}[ht]
d140 1
a140 1
\rule[.1in]{\textwidth}{0.01in} 
d142 1
a143 1
\rule[.1in]{\textwidth}{0.01in} 
d147 22
d173 5
a177 1
\ref{adjunct-fig}.
d179 1
a179 1
\begin{figure}[ht]
d181 8
a188 5
\rule[.1in]{\textwidth}{0.01in} 
\psfig{figure=ps/intro-files/schematic-feat-adjunction.ps,height=2.0in}
\caption{Adjunction in FB-LTAG}
\label{adjunct-fig}
\rule[.1in]{\textwidth}{0.01in} 
a207 11
\begin{figure*}[ht]
\centering
\begin{tabular}{cc}
{\psfig{figure=ps/intro-files/think-feat.ps,height=5.0in}}  &
{\psfig{figure=ps/intro-files/want-feat.ps,height=5.0in}} \\
{\it think} tree&{\it want} tree\\
\end{tabular}\\
\caption {Lexicalized Elementary Trees with Features}
\label {lex-with-features}
\end{figure*}

d209 6
a214 6
indicative sentential complement, as you might find in a sentence such as {\it
John thinks that Mary loves Sally}.  {\it Want} takes a sentential complement
as well, but an infinitive one, as in {\it John wants to love Mary}.  This
distinction is easily captured in the features and passed to other nodes to
constrain which trees this tree can adjoin into, both cutting down the number
of separate trees needed and enforcing conceptual Selective Adjunctions (SA).
@


1.4
log
@Changed the name of a reference (kb83 --> kaplan83).
@
text
@d174 14
a187 12
The embedding of the TAG formalism in a unification framework allows us to
dynamically specify local constraints that would have otherwise had to have
been made statically within the trees.  Constraints that verbs make on their
complements, for instance, can be implemented through the feature structures.
The notions of Obligatory and Selective Adjunction, crucial to the formation of
lexicalized grammars, can also be handled through the use of
features\footnote{The remaining constraint, Null Adjunction (NA), must still be
specified directly on a node.} Perhaps more important to developing a grammar,
though, is that the trees can serve as a schemata to be instantiated with
lexical-specific features when an anchor is associated with the tree.  To
illustrate this, Figure \ref{lex-with-features} shows the same tree lexicalized
with two different verbs, each of which instantiates the features of the tree
@


1.3
log
@Moved .ps files into separate directories for each file, and had to change
the psfig commands to correspond.
@
text
@d103 2
a104 2
constraint \cite{kb83}. As consequences of our definition, each structure has
at least one lexical item (its anchor) attached to it and all sentences are
@


1.2
log
@Pass 1 finished.  Includes Christy's changes.  Looks pretty decent.
@
text
@d29 1
a29 1
\psfig{figure=ps/schematic-elem-trees.ps,height=2.0in}
d58 1
a58 1
\psfig{figure=ps/schematic-subst2.ps,height=2.0in}
d73 1
a73 1
\psfig{figure=ps/schematic-adjunction2.ps,height=2.0in}
d114 4
a117 4
{{\psfig{figure=ps/john.ps,height=1.0in}}\label{fig1a}}  &
{{\psfig{figure=ps/walked.ps,height=1.4in}}\label{fig1b}}  & 
{{\psfig{figure=ps/to.ps,height=1.7in}} \label{fig1c} }  & 
{{\psfig{figure=ps/philly.ps,height=1.0in}} \label{fig1d}} \\
d152 1
a152 1
\psfig{figure=ps/schematic-feat-subst.ps,height=2.0in}
d167 1
a167 1
\psfig{figure=ps/schematic-feat-adjunction.ps,height=2.0in}
d191 2
a192 2
{\psfig{figure=ps/think-feat.ps,height=5.0in}}  &
{\psfig{figure=ps/want-feat.ps,height=5.0in}} \\
@


1.1
log
@Initial revision
@
text
@d2 12
a14 17
The English grammar described in this report is based on the TAG formalism developed in
Joshi Levy, Takahashi\shortcite{josh75}. As first shown by Joshi (1985) and Kroch and Joshi (1985), the properties of TAGs permit us to encapsulate diverse syntactic phenomena in a very natural way. TAG's extended domain of locality and its factoring of recursion from local dependencies lead, among other things, to a localization of so-called unbounded dependencies.
The primitive elements of the TAG formalism are known as {\sc
elementary trees}.  Elementary trees are of two types: {\sc initial
trees} and {\sc auxiliary trees}.  In describing natural language,
{\sc initial trees} are phrase structure trees of simple sentences
containing no recursion, while recursive structures are represented by
{\sc auxiliary trees} as illustrated in Figure~\ref{fig1}.  Initial
trees are defined as having exactly one terminal node on their
frontier, the anchor (indicated by $\beta$, and as having all ohter nodes on the frontier
marked as substitution sitesNodes on
the frontier of an {\sc initial tree} would be marked by a
($\downarrow$), to indicate a site for substitution while exactly one
node of an {\sc auxiliary tree} will be marked by an ($\ast$), to
indicate a foot node. Further, the foot node has the same label as the
root node of the tree. The trees define the domain of locality over
which constraints are specified.
d16 9
d26 8
a33 1
 The trees in I  are called initial trees. Initial trees represent minimal linguistic structures which are defined to have at least one terminal at the frontier (the anchor) and to have all non-terminal nodes at the frontier  filled by substitution.  An initial tree is called an X-type initial tree if its root is labeled with type X.  All basic categories or constituents which serve as arguments to more complex initial or auxiliary trees are X-type initial trees. A particular case is the S-type initial trees (e.g. the left tree in Figure~\ref{elt-tree}). They are rooted in S, and it is a requirement of the grammar that a valid input string has to be derived from at least one S-type initial tree. The trees in A  are called {\bf auxiliary trees}.They can represent constituents that are adjuncts to basic structures(e.g. adverbials). They can also represent basic sentential structures corresponding to verbs or predicates taking sentential complements.Auxiliary trees (e.g. the right tree in Figure~3) are characterized as follows:\begin{list}{$\bullet$}{\setlength{\topsep}{0in} \setlength{\itemsep}{0in}}\item internal nodes are labeled by non-terminals;\item leaf nodes are labeled by terminals or by  non-terminal nodesfilled by substitution except for exactly one node (called the {\bf footnode}) labeled by a non-terminal on which only adjunction can apply;furthermore the label of the foot node is the same as the label of theroot node.\footnote{A null adjunction constraint (NA) is putsystematically on the footnode of an auxiliary tree. This disallowsadjunction of a tree on the footnode.}\end{list}The {\bf tree set} of a TAG $G$, ${\cal T}(G)$ is defined to be theset of all derived trees starting from S-type initial trees in $I$ whosefrontier consists of terminal nodes (all substitution nodes having beenfilled). The {\bf string language} generated by a TAG, ${\cal L}(G)$,is defined to be the set of all terminal strings on the frontier of thetrees in ${\cal T}(G)$.
d35 10
a44 11
\subsection{Lexicalization}
Most current linguistic theories give lexical accounts of several
phenomena that used to be considered purely syntactic. The information
put in the lexicon is thereby increased in both amount and complexity:
see, for example, lexical rules in LFG (Bresnan and Kaplan, 1983)\nocite{bk83}, GPSG
(Gazdar, Klein, Pullum and Sag, 1985)\nocite{gkps85}, HPSG (Pollard
and Sag, 1987)\nocite{ps87}, Combinatory Categorial Grammars (Steedman
1985, 1988\nocite{st88}), Karttunen's version of Categorial Grammar
\nocite{kart86}(Karttunen 1986, 1988), some versions of GB theory
(Chomsky 1981\nocite{c81}), and Lexicon-Grammars (Gross 1984).
\nocite{gross84}
d46 8
a53 5
Following Schabes, Abeill and Joshi (1988) we say that a grammar is
	`lexicalized' if it consists of:\footnote{By `lexicalization' we mean
that in each structure there is a lexical item that is realized. We do
not mean simply adding feature structures (such as head) and unification
equations to the rules of the formalism.}
d55 8
d64 5
a68 16
\begin{list}{$\bullet$}{\setlength{\topsep}{0in} \setlength{\itemsep}{0in}}
\item a finite
set of structures each associated with a lexical item; each lexical
item will be called the {\it anchor}\footnote{In previous
publications, the term `head' was used instead of the term `anchor'.
From now on, we will use the term anchor instead; the term `head'
introduces some confusion because the lexical items which are the
source of the elementary trees may not necessarily be the same as the
traditional syntactic head of those structures. In fact, the notion of
anchor is in some ways closer to the notion of function in Categorial Grammars.} of
the corresponding structure; the structures define the domain of
locality over which constraints are specified; constraints are local
with respect to their anchor;
\item an operation or operations for composing
the structures.
\end{list}
d70 8
a77 1
\vspace{0.5cm}
d79 5
a83 1
`Lexicalized' grammars (Schabes, Abeill\'{e} and Joshi,1988)\nocite{saj88}, systematically associate each elementary structure with a lexical anchor. These elementary structures specify extended domains of locality (as compared to CFGs) over which constraints can be stated. The `grammar', consists of a lexicon where each lexical item is associated with a finite number of structures for which that item is the anchor. There are no separate grammar rules at this level of description, although there are, of course, `rules'which tell us how these structures are combined.  In general, this isthe level of description that we will be describing in this paper. Ata higher level of description, the grammar rules and principles that are implicit in the form of the lexicon would be stated explicitly. For example, there are principles which govern which trees are groupedtogether into tree families, and rules which describe the relations between structure types across tree families (see subsection 2.1for a discussion of tree families.) The information explicitly provided in this more abstract representation of the grammar may bethought of as an interpretation of the data in the lower-level representation.\footnote{There may also be some linguistic generalizations which can not be stated as an explicit representation of implicit lexical information.  These would likely be statements concerning the constraints on syntactic structures that are needed to evaluate the acceptability of a new lexical item or structure.  We have not yet needed to account for any statements of this kind.}
d85 1
a85 1
Not every grammar is in a `lexicalized' form.\footnote{Notice the similarity of the definition of `lexicalized' grammar with the off line parsibility constraint (Kaplan and Bresnan 1983)\nocite{kb83}. As consequences of our definition, each structure has at least one lexical item (its anchor) attached to it and all sentences are finitely ambiguous.} In the process of lexicalizing a grammar,the `lexicalized' grammar is required to produce not only the same language as the original grammar, but also the same structures (or tree set).
d87 6
a92 1
For example, a CFG, in general, will not be in a `lexicalized' form.The domain of locality of CFGs can be easily extended by using a tree rewriting grammar (Schabes, Abeill\'{e} and Joshi, 1988) that uses only substitution as a combining operation. This tree rewriting grammar consists of a set of trees that are not restricted to be of depth one(as in CFGs). Substitution can take place only on non-terminal nodes ofthe frontier of each tree. Substitution replaces a node marked forsubstitution by a tree rooted by the same label as the node (seeFigure~\ref{operations}; the substitution node is marked by a down arrow$\downarrow$).
d94 6
a99 1
However, in the general case, CFGs cannot be `lexicalized', if only substitution is used (for further explanation why, the reader isreferred to Schabes, Abeill\'{e} and Joshi, 1988).Furthermore, in general, there is not enough freedom to choose the anchor of each structure. This is important because we want the choiceof the anchor for a given structure to be determined on purely linguistic grounds.
d101 8
a108 1
If adjunction is used as an additional operation to combine these structures, CFGs can be lexicalized. Adjunction builds a new tree from an auxiliary tree $\beta$ and a tree $\alpha$. It inserts anauxiliary tree into another tree (see Figure~\ref{operations}).Adjunction is more powerful than substitution. It can weakly simulate substitution, but it also generates languages that could not be generatedwith substitution.\footnote{It is also possible to encode a context-free grammar with auxiliary trees using adjunction only. However, although the languages correspond, the set of trees do not correspond.}
d110 14
a123 26
\begin{figure}[htb]
\begin{tabular}{|ccc||ccc|}
\hline
\multicolumn{3}{|c||}{\psfig{figure=figures/subst.text,width=3.0in}} &
\multicolumn{3}{|c||}{\psfig{figure=figures/adjunction.text,width=3.0in}}
& & & & &
\multicolumn{3}{|c||}{{\it Substitution}} &\multicolumn{3}{c|}{{\it
Adjunction}} 
\hline
\hline
\psfig{figure=figures/loved.fig,height=2.8cm} &
\psfig{figure=figures/woman.fig,height=1.95cm} 
\raisebox{1.0cm}{$\longrightarrow$} &
\psfig{figure=figures/loved-woman.fig,height=3.4cm}&
\psfig{figure=figures/loved.fig,height=2.8cm} &
\psfig{figure=figures/has-BvVX.fig,height=1.95cm} 
\raisebox{2.0cm}{$\longrightarrow$} &
\psfig{figure=figures/has-loved.fig,height=3.4cm}
& & & & &
\multicolumn{3}{|c||}{{\it Example of Substitution}}
&\multicolumn{3}{c|}{{\it Example of Adjunction}}  
\hline
\end{tabular}
\caption{{\it Combining Operations}}
\label{operations}
\end{figure}
d125 4
a128 33
% 
% \begin{figure}[htb]
% \begin{tabular}{|c||c|}
% \hline
% \psfig{figure=figures/subst.text,width=3.0in} &
% \psfig{figure=figures/adjunction.text,width=3.0in}
% & 
% {\it Substitution} & {\it Adjunction}
% \hline
% \end{tabular}
% \caption{{\it Combining operations}}
% \label{operations}
% \end{figure}
% 
% 							
% \begin{figure}[htb]
% \begin{tabular}{|ccc||ccc|}
% \hline
% \psfig{figure=figures/loved.fig,height=2.8cm} &
% \psfig{figure=figures/woman.fig,height=1.95cm} 
% \raisebox{1.0cm}{$\longrightarrow$} &
% \psfig{figure=figures/loved-woman.fig,height=3.4cm}&
% \psfig{figure=figures/loved.fig,height=2.8cm} &
% \psfig{figure=figures/has-BvVX.fig,height=1.95cm} 
% \raisebox{2.0cm}{$\longrightarrow$} &
% \psfig{figure=figures/has-loved.fig,height=3.4cm}
% & & & & &
% \multicolumn{3}{|c||}{{\it Substitution}} &\multicolumn{3}{c|}{{\it Adjunction}} 
% \hline
% \end{tabular}
% \caption{{\it Examples of Substitution and Adjunction}}
% \label{examples}
% \end{figure}
d131 1
a131 1
Substitution and adjunction enable us to lexicalize CFGs. The anchors can be  chosen on purely linguistic grounds (Schabes, Abeill\'{e} and Joshi, 1988).  The resulting system now falls in the class of mildly context-sensitive languages (Joshi, 1985, and Joshi, Vijayshanker and Weir,1990)\nocite{j83,jvw90}. Elementary structures of extended domain of locality combined with substitution and adjunction yield LexicalizedTAGs (LTAGs).
d133 7
a139 1
TAGs were first introduced by Joshi, Levy and Takahashi(1975)\nocite{jlt75} and Joshi (1985)\nocite{j83}.For more details on the original definition of TAGs, we refer the reader to Joshi (1985), Kroch and Joshi (1985)\nocite{kj85}, or Vijay-Shanker(1987)\nocite{v87}.It is known that Tree Adjoining Languages (TALs) are mildly context sensitive.TALs properly contain context-free languages.
d141 7
a147 6
TAGs with substitution and adjunction are naturally lexicalized becausethey use an extended domain of locality.\footnote{In some earlier workof Joshi (1969, 1973)\nocite{joshi69}\nocite{joshi73}, the use of the two operations `adjoining' and `replacement' (a restricted case of substitution) was investigated both mathematically and linguistically.  However, these investigations dealt with string rewriting systems and not tree rewriting systems.} A Lexicalized Tree Adjoining Grammar is a tree-based system that consists of two finite sets of trees: a set of initial trees, $I$ and a set of auxiliary trees $A$ (seeFigure~\ref{elt-tree}). The trees in $I \cup A$ are called {\bfelementary trees}. Each elementary tree is constrained to have at least  one terminal symbol which acts as its anchor.
 \begin{figure}[htb]
\begin{center}
\begin{tabular}{|c|}
\hline
\psfig{figure=figures/lex-elementary.fig,height=3.5cm}
d149 8
a156 6
\hline
\end{tabular}
\end{center}
 \caption{{\it Schematic initial and auxiliary trees}}
 \label{elt-tree}
 \end{figure}
d158 5
d164 8
a171 1
The trees in $I$ are called {\bf initialtrees}. Initial trees represent minimal linguistic structures which aredefined to have at least one terminal at the frontier (the anchor)and to have all non-terminal nodes at the frontier  filled by substitution.An initial tree is called an X-type initial tree if its root is labeled with type X.All basic categories or constituents which serve as arguments to more complex initial or auxiliary trees are X-type initial trees. A particular case is the S-type initialtrees (e.g. the left tree in Figure~\ref{elt-tree}). They are rooted in $S$, and it is a requirement of the grammar that a valid input string has to be derived from at least one S-type initial tree. 
d174 13
a186 11
The trees in $A$ are called {\bf auxiliary trees}.They can represent constituents that are adjuncts to basic structures(e.g. adverbials). They can also represent basic sentential structures corresponding to verbs or predicates taking sentential complements.Auxiliary trees (e.g. the right tree in Figure~3) are characterized as follows:
\begin{list}{$\bullet$}{\setlength{\topsep}{0in} \setlength{\itemsep}{0in}}
\item internal nodes are labeled by non-terminals;
\item leaf nodes are labeled by terminals or by  non-terminal nodes
filled by substitution except for exactly one node (called the {\bf foot
node}) labeled by a non-terminal on which only adjunction can apply;
furthermore the label of the foot node is the same as the label of the
root node.\footnote{A null adjunction constraint (NA) is put
systematically on the footnode of an auxiliary tree. This disallows
adjunction of a tree on the footnode.}
\end{list}
d188 10
d199 9
a207 1
The {\bf tree set} of a TAG $G$, ${\cal T}(G)$ is defined to be the set of all derived trees starting from S-type initial trees in $I$ whose frontier consists of terminal nodes (all substitution nodes having been filled). The {\bf string language} generated by a TAG, ${\cal L}(G)$, is defined to be the set of all terminal strings on the frontier of the trees in ${\cal T}(G)$.
@
